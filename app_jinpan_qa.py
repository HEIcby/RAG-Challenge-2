#!/usr/bin/env python3
"""
é‡‘ç›˜ç§‘æŠ€ RAG é—®ç­”ç³»ç»Ÿ - Streamlit å‰ç«¯
åŸºäº val_jinpan_colab.ipynb çš„äº¤äº’å¼æœ¬åœ°å‰ç«¯
"""

import streamlit as st
import sys
import os
from pathlib import Path
import json
from datetime import datetime
import traceback
import pandas as pd
from typing import List
try:
    import fitz  # PyMuPDF
except ImportError:
    fitz = None
from PIL import Image
import io

# é¢„é…ç½® API Keys
os.environ["DASHSCOPE_API_KEY"] = "sk-6a44d15e56dd4007945ccc41b97b499c"
os.environ["GOOGLE_API_KEY"] = "AIzaSyA4pIV3SB-OWYfGZoZjDM_8dbU6Zycpaz8"

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
root_dir = Path(__file__).parent
sys.path.insert(0, str(root_dir))

from src.questions_processing import QuestionsProcessor
from src.api_requests import APIProcessor

# åŠ è½½ benchmark æ ‡å‡†ç­”æ¡ˆæ˜ å°„
@st.cache_data
def load_benchmark_answers(benchmark_path: str) -> dict:
    """
    åŠ è½½ benchmark CSVï¼Œå»ºç«‹ é—®é¢˜ -> æ ‡å‡†ç­”æ¡ˆ çš„æ˜ å°„
    """
    import csv
    import re
    mapping = {}
    try:
        with open(benchmark_path, 'r', encoding='utf-8-sig') as f:
            reader = csv.DictReader(f)
            for row in reader:
                question = row.get('é—®é¢˜', '').strip()
                answer = row.get('æ ‡å‡†å›ç­”', '').strip()
                if question and answer:
                    # æ¸…ç†é—®é¢˜æ–‡æœ¬ç”¨äºåŒ¹é…
                    question_clean = re.sub(r'\s+', ' ', question)
                    mapping[question_clean] = answer
    except Exception as e:
        st.warning(f"åŠ è½½ benchmark å¤±è´¥: {e}")
    return mapping

# ä» questions.csv æˆ– benchmark ä¸­è·å–æ ‡å‡†ç­”æ¡ˆ
@st.cache_data
def get_standard_answer(question: str, questions_df: pd.DataFrame = None, benchmark_map: dict = None) -> str:
    """
    è·å–é—®é¢˜çš„æ ‡å‡†ç­”æ¡ˆ
    ä¼˜å…ˆä» questions.csv çš„"æ ‡å‡†å›ç­”"åˆ—è·å–ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä» benchmark ä¸­åŒ¹é…
    """
    import re
    
    # æ¸…ç†é—®é¢˜æ–‡æœ¬
    question_clean = re.sub(r'\s+', ' ', question.strip())
    
    # 1. å…ˆä» questions.csv ä¸­æŸ¥æ‰¾
    if questions_df is not None:
        for idx, row in questions_df.iterrows():
            if question_clean == re.sub(r'\s+', ' ', str(row.get('æé—®å†…å®¹', '')).strip()):
                standard_answer = row.get('æ ‡å‡†å›ç­”', '')
                if standard_answer and str(standard_answer).strip():
                    return str(standard_answer).strip()
    
    # 2. ä» benchmark ä¸­åŒ¹é…
    if benchmark_map:
        # ç²¾ç¡®åŒ¹é…
        if question_clean in benchmark_map:
            return benchmark_map[question_clean]
        
        # æ¨¡ç³ŠåŒ¹é…ï¼ˆå»é™¤æ ‡ç‚¹ç¬¦å·ï¼‰
        question_normalized = re.sub(r'[^\w]', '', question_clean)
        for bq, answer in benchmark_map.items():
            bq_normalized = re.sub(r'[^\w]', '', bq)
            if question_normalized == bq_normalized:
                return answer
    
    return ""

# åŠ è½½ subset.csv æ˜ å°„ï¼ˆSHA1 -> æ–‡æ¡£ä¿¡æ¯ï¼‰
@st.cache_data
def load_document_mapping(subset_path: str) -> dict:
    """
    åŠ è½½ subset.csvï¼Œå»ºç«‹ SHA1 -> {company_name, year} çš„æ˜ å°„
    """
    import csv
    mapping = {}
    try:
        with open(subset_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                sha1 = row.get('sha1', '')
                company_name = row.get('company_name', '')
                year = row.get('year', '')
                if sha1:
                    mapping[sha1] = {
                        'company_name': company_name,
                        'year': year,
                        'display_name': f"{company_name} {year}å¹´æŠ¥" if year else company_name
                    }
    except Exception as e:
        st.error(f"åŠ è½½ subset.csv å¤±è´¥: {e}")
    return mapping

# è·å–å¯ç”¨å¹´ä»½åˆ—è¡¨
@st.cache_data
def get_available_years(subset_path: str, company_name: str) -> List[int]:
    """
    ä» subset.csv è·å–æŒ‡å®šå…¬å¸çš„æ‰€æœ‰å¯ç”¨å¹´ä»½
    
    Args:
        subset_path: subset.csv æ–‡ä»¶è·¯å¾„
        company_name: å…¬å¸åç§°
    
    Returns:
        æ’åºåçš„å¹´ä»½åˆ—è¡¨
    """
    import csv
    years = set()
    try:
        with open(subset_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                if row.get('company_name', '') == company_name:
                    year_str = row.get('year', '').strip()
                    if year_str:
                        try:
                            years.add(int(year_str))
                        except ValueError:
                            pass
    except Exception as e:
        st.warning(f"è·å–å¯ç”¨å¹´ä»½å¤±è´¥: {e}")
    return sorted(list(years))

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="é‡‘ç›˜ç§‘æŠ€ RAG é—®ç­”ç³»ç»Ÿ",
    page_icon="ğŸ¢",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSS
st.markdown("""
    <style>
    /* å¢åŠ ä¾§è¾¹æ å®½åº¦ */
    [data-testid="stSidebar"] {
        min-width: 400px;
        max-width: 450px;
    }
    .main {
        padding: 0rem 1rem;
    }
    .stAlert {
        margin-top: 1rem;
    }
    .answer-box {
        background-color: #f8f9fa;
        padding: 1.5rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
        border: 1px solid #dee2e6;
        color: #212529;
    }
    .question-box {
        background-color: #cfe2ff;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
        border-left: 4px solid #0d6efd;
        color: #052c65;
    }
    .reference-box {
        background-color: #fff3cd;
        padding: 0.8rem;
        border-radius: 0.3rem;
        margin: 0.3rem 0;
        font-size: 0.9rem;
        border: 1px solid #ffecb5;
        color: #664d03;
    }
    /* æ”¹å–„æŒ‰é’®å¯¹æ¯”åº¦ */
    .stButton > button {
        border: 1px solid #dee2e6;
    }
    /* æ”¹å–„æ–‡æœ¬æ¡†å¯¹æ¯”åº¦ */
    .stTextInput > div > div > input {
        background-color: #ffffff;
        border: 2px solid #ced4da;
        color: #212529;
    }
    /* Tab æ ‡ç­¾æ ·å¼ä¼˜åŒ– */
    .stTabs [data-baseweb="tab-list"] button {
        color: #495057;
        font-weight: 500;
    }
    .stTabs [data-baseweb="tab-list"] button[aria-selected="true"] {
        color: #0d6efd;
    }
    /* æˆåŠŸ/è­¦å‘Š/ä¿¡æ¯æ¡†å¯¹æ¯”åº¦å¢å¼º */
    .stSuccess {
        background-color: #d1e7dd;
        color: #0a3622;
    }
    .stWarning {
        background-color: #fff3cd;
        color: #664d03;
    }
    .stInfo {
        background-color: #cfe2ff;
        color: #052c65;
    }
    </style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–session state
if 'processor' not in st.session_state:
    st.session_state.processor = None
if 'history' not in st.session_state:
    st.session_state.history = []
if 'initialized' not in st.session_state:
    st.session_state.initialized = False
if 'current_question' not in st.session_state:
    st.session_state.current_question = ""
if 'current_schema' not in st.session_state:
    st.session_state.current_schema = "jingpan"
if 'example_clicked' not in st.session_state:
    st.session_state.example_clicked = False
if 'widget_key_counter' not in st.session_state:
    st.session_state.widget_key_counter = 0
if 'enable_multi_turn' not in st.session_state:
    st.session_state.enable_multi_turn = False  # é»˜è®¤å…³é—­å¤šè½®å¯¹è¯
if 'context_turns' not in st.session_state:
    st.session_state.context_turns = 3  # é»˜è®¤ä¿ç•™3è½®å†å²
if 'flow_step_selector' not in st.session_state:
    st.session_state.flow_step_selector = 'overview'

def initialize_system():
    """åˆå§‹åŒ–RAGé—®ç­”ç³»ç»Ÿ"""
    try:
        root_path = Path("data/val_set")
        company_name = "é‡‘ç›˜ç§‘æŠ€"
        
        # æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å­˜åœ¨
        vector_db_dir = root_path / "databases" / "vector_dbs"
        documents_dir = root_path / "databases" / "chunked_reports"
        subset_path = root_path / "subset.csv"
        
        if not documents_dir.exists() or not vector_db_dir.exists():
            st.error("âŒ æ•°æ®åº“ä¸å­˜åœ¨ï¼è¯·å…ˆè¿è¡Œ main.py å¤„ç† PDF æ–‡ä»¶")
            return False
        
        # è·å–é…ç½®
        config = st.session_state.config
        
        with st.spinner("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–é—®ç­”ç³»ç»Ÿ..."):
            processor = QuestionsProcessor(
                vector_db_dir=vector_db_dir,
                documents_dir=documents_dir,
                questions_file_path=None,
                new_challenge_pipeline=True,
                subset_path=subset_path,
                parent_document_retrieval=True,
                llm_reranking=config['llm_reranking'],
                llm_reranking_sample_size=config.get('rerank_sample_size', 50),
                top_n_retrieval=config['top_n_retrieval'],
                parallel_requests=config.get('parallel_requests', 4),
                api_provider=config['api_provider'],
                answering_model=config['answering_model'],
                full_context=False,
                use_hyde=config['use_hyde'],
                use_multi_query=config['use_multi_query'],
                multi_query_methods=config.get('multi_query_methods'),
                expand_upstream=config.get('expand_upstream', False),
                expand_top_k=config.get('expand_top_k', 5),
                expand_context_size=config.get('expand_context_size', 1)
            )
            
            st.session_state.processor = processor
            st.session_state.company_name = company_name
            st.session_state.initialized = True
            
        return True
    except Exception as e:
        st.error(f"âŒ åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        with st.expander("æŸ¥çœ‹è¯¦ç»†é”™è¯¯"):
            st.code(traceback.format_exc())
        return False

def get_pdf_page_image(pdf_path: str, page_num: int, dpi: int = 150):
    """
    ä»PDFæå–æŒ‡å®šé¡µç çš„å›¾ç‰‡ï¼ˆä½¿ç”¨PyMuPDFï¼‰
    
    Args:
        pdf_path: PDFæ–‡ä»¶è·¯å¾„
        page_num: é¡µç ç´¢å¼•ï¼ˆ**0-based**ï¼Œç¬¬1é¡µ=0ï¼Œç¬¬2é¡µ=1ï¼Œä»¥æ­¤ç±»æ¨ï¼‰
        dpi: å›¾ç‰‡åˆ†è¾¨ç‡ï¼ˆå®é™…ä½¿ç”¨zoomå‚æ•°ï¼‰
    
    Returns:
        PIL Imageå¯¹è±¡æˆ–None
    """
    if fitz is None:
        st.warning("âš ï¸ PyMuPDFæœªå®‰è£…ï¼Œæ— æ³•æ˜¾ç¤ºPDFé¡µé¢å›¾ç‰‡")
        return None
    
    try:
        # æ‰“å¼€PDFæ–‡æ¡£
        doc = fitz.open(pdf_path)
        
        # æ£€æŸ¥é¡µç æ˜¯å¦æœ‰æ•ˆ
        if page_num < 0 or page_num >= len(doc):
            st.warning(f"âš ï¸ é¡µç  {page_num} è¶…å‡ºèŒƒå›´ (æ€»é¡µæ•°: {len(doc)})")
            return None
        
        # è·å–æŒ‡å®šé¡µé¢
        page = doc[page_num]
        
        # è®¾ç½®ç¼©æ”¾æ¯”ä¾‹ (dpi/72ï¼Œå› ä¸ºPDFé»˜è®¤æ˜¯72dpi)
        zoom = dpi / 72
        mat = fitz.Matrix(zoom, zoom)
        
        # æ¸²æŸ“é¡µé¢ä¸ºå›¾ç‰‡
        pix = page.get_pixmap(matrix=mat)
        
        # è½¬æ¢ä¸ºPIL Image
        img_data = pix.tobytes("png")
        img = Image.open(io.BytesIO(img_data))
        
        doc.close()
        return img
        
    except Exception as e:
        st.warning(f"âš ï¸ æ— æ³•æå–PDFé¡µé¢å›¾ç‰‡: {str(e)}")
        return None

def format_answer_display(answer_dict: dict, question: str = ""):
    """æ ¼å¼åŒ–å¹¶æ˜¾ç¤ºç­”æ¡ˆ"""
    # è·å–ç­”æ¡ˆ
    answer = answer_dict.get("final_answer", answer_dict.get("answer", "N/A"))
    
    # è·å–æ ‡å‡†ç­”æ¡ˆ
    standard_answer = ""
    if question:
        try:
            questions_df = pd.read_csv("data/val_set/questions_selected_100.csv")
            benchmark_map = load_benchmark_answers("é‡‘ç›˜è´¢æŠ¥æŸ¥è¯¢åœºæ™¯é—®é¢˜benchmark-åŸå…ˆçš„è¡¨æ ¼.csv")
            standard_answer = get_standard_answer(question, questions_df, benchmark_map)
        except Exception as e:
            st.warning(f"è·å–æ ‡å‡†ç­”æ¡ˆå¤±è´¥: {e}")
    
    # è·å–è®¡æ—¶ä¿¡æ¯
    timing = answer_dict.get("timing", {})
    
    # ä¸»ç­”æ¡ˆ - ä½¿ç”¨æ›´æ˜æ˜¾çš„å¯¹æ¯”è‰²
    st.markdown("### ğŸ“Š ç­”æ¡ˆ")
    
    # å¹¶æ’æ˜¾ç¤ºRAGç­”æ¡ˆå’Œæ ‡å‡†ç­”æ¡ˆ
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**ğŸ¤– RAGç”Ÿæˆçš„ç­”æ¡ˆ**")
        st.markdown(f'<div class="answer-box"><h3 style="color: #0d6efd; margin-top: 0; margin-bottom: 0;">ğŸ’¡ {answer}</h3></div>', 
                unsafe_allow_html=True)
    
    with col2:
        st.markdown("**âœ… æ ‡å‡†ç­”æ¡ˆ**")
        if standard_answer:
            st.markdown(f'<div class="answer-box" style="background-color: #d1e7dd;"><h3 style="color: #0a3622; margin-top: 0; margin-bottom: 0;">ğŸ“‹ {standard_answer}</h3></div>', 
                        unsafe_allow_html=True)
        else:
            st.info("æš‚æ— æ ‡å‡†ç­”æ¡ˆ")
    
    # æ˜¾ç¤ºè®¡æ—¶ä¿¡æ¯ï¼ˆç®€æ´çš„æŒ‡æ ‡å¡ç‰‡ï¼‰
    if timing:
        st.markdown("---")
        st.markdown("### â±ï¸ æ€§èƒ½æŒ‡æ ‡")
        
        # è®¡ç®—å…³é”®é˜¶æ®µçš„ç”¨æ—¶
        total_time = timing.get("total_time", 0.0)
        retrieval_time = timing.get("retrieval", 0.0)  # æ€»æ£€ç´¢æ—¶é—´ï¼ˆåŒ…å«HYDEã€Multi-Queryã€å‘é‡æœç´¢ï¼‰
        hyde_time = timing.get("hyde_expansion", 0.0)
        multi_query_time = timing.get("multi_query_expansion", 0.0)
        vector_search_time = timing.get("vector_search", 0.0)
        llm_reranking_time = timing.get("llm_reranking", 0.0)
        generate_answer_time = timing.get("generate_answer", 0.0)
        
        # å‘é‡æ£€ç´¢æ€»æ—¶é—´ï¼šå¦‚æœvector_searchå•ç‹¬ç»Ÿè®¡ï¼Œåˆ™ç›¸åŠ ï¼›å¦åˆ™ä½¿ç”¨retrieval_time
        if vector_search_time > 0:
            vector_retrieval_total = hyde_time + multi_query_time + vector_search_time
        else:
            # vector_searchæœªå•ç‹¬ç»Ÿè®¡ï¼Œä½¿ç”¨æ€»æ£€ç´¢æ—¶é—´
            vector_retrieval_total = retrieval_time
        
        # ä½¿ç”¨4åˆ—å¸ƒå±€å±•ç¤ºå…³é”®æŒ‡æ ‡
        metric_col1, metric_col2, metric_col3, metric_col4 = st.columns(4)
        
        with metric_col1:
            st.metric("æ€»ç”¨æ—¶", f"{total_time:.2f}s" if total_time > 0 else "N/A")
        
        with metric_col2:
            st.metric("å‘é‡æ£€ç´¢", f"{vector_retrieval_total:.2f}s" if vector_retrieval_total > 0 else "N/A")
        
        with metric_col3:
            if llm_reranking_time > 0:
                st.metric("LLMé‡æ’åº", f"{llm_reranking_time:.2f}s")
            else:
                st.metric("LLMé‡æ’åº", "æœªä½¿ç”¨")
        
        with metric_col4:
            st.metric("ç”Ÿæˆç­”æ¡ˆ", f"{generate_answer_time:.2f}s" if generate_answer_time > 0 else "N/A")
        
        reranker_stats = answer_dict.get("reranker_stats") or timing.get("reranker_stats")
        if reranker_stats:
            st.markdown("#### ğŸ¤– LLMé‡æ’åºç»Ÿè®¡")
            stat_cols = st.columns(3)
            success_rate = reranker_stats.get("success_rate", 0.0) * 100
            stat_cols[0].metric("æˆåŠŸç‡", f"{success_rate:.1f}%")
            stat_cols[1].metric("è¯·æ±‚æ€»æ•°", reranker_stats.get("total_requests", 0))
            stat_cols[2].metric(
                "å¹³å‡LLMè€—æ—¶",
                f"{reranker_stats.get('avg_llm_latency', 0.0):.2f}s"
            )
            st.caption(
                f"å¹¶å‘ä¸Šé™: {reranker_stats.get('max_concurrent_requests', 'N/A')} | "
                f"QPSé™åˆ¶: {reranker_stats.get('request_rate_limit', 'N/A')} | "
                f"æ‰¹æ¬¡å›é€€: {reranker_stats.get('batch_fallbacks', 0)} | "
                f"ç¼ºå¤±æ’åè¡¥å¿: {reranker_stats.get('missing_rankings', 0)}"
            )
            if reranker_stats.get("last_error"):
                st.info(f"æœ€è¿‘é”™è¯¯ï¼š{reranker_stats['last_error']}")

        # å¯é€‰ï¼šä½¿ç”¨expanderå±•ç¤ºæ›´è¯¦ç»†çš„å„é˜¶æ®µç”¨æ—¶ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        with st.expander("ğŸ“Š æŸ¥çœ‹è¯¦ç»†è®¡æ—¶ä¿¡æ¯"):
            timing_df = pd.DataFrame([
                {'é˜¶æ®µ': 'åˆå§‹åŒ–æ£€ç´¢å™¨', 'ç”¨æ—¶(ç§’)': timing.get('init_retriever', 0.0)},
                {'é˜¶æ®µ': 'HYDEæ‰©å±•', 'ç”¨æ—¶(ç§’)': timing.get('hyde_expansion', 0.0)},
                {'é˜¶æ®µ': 'Multi-Queryæ‰©å±•', 'ç”¨æ—¶(ç§’)': timing.get('multi_query_expansion', 0.0)},
                {'é˜¶æ®µ': 'å‘é‡æœç´¢', 'ç”¨æ—¶(ç§’)': timing.get('vector_search', 0.0)},
                {'é˜¶æ®µ': 'å‘é‡æ£€ç´¢æ€»æ—¶é—´', 'ç”¨æ—¶(ç§’)': timing.get('retrieval', 0.0)},
                {'é˜¶æ®µ': 'LLMé‡æ’åº', 'ç”¨æ—¶(ç§’)': timing.get('llm_reranking', 0.0)},
                {'é˜¶æ®µ': 'ä¸Šæ¸¸æ‰©å……', 'ç”¨æ—¶(ç§’)': timing.get('upstream_expansion', 0.0)},
                {'é˜¶æ®µ': 'æ ¼å¼åŒ–ç»“æœ', 'ç”¨æ—¶(ç§’)': timing.get('format_results', 0.0)},
                {'é˜¶æ®µ': 'ç”Ÿæˆç­”æ¡ˆ', 'ç”¨æ—¶(ç§’)': timing.get('generate_answer', 0.0)},
                {'é˜¶æ®µ': 'æ€»ç”¨æ—¶', 'ç”¨æ—¶(ç§’)': timing.get('total_time', 0.0)},
            ])
            st.dataframe(timing_df, use_container_width=True, hide_index=True)
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ” åˆ†æè¿‡ç¨‹", "ğŸ“ æ¨ç†æ€»ç»“", "ğŸ“š LLMé€‰ç”¨çš„å‚è€ƒ", "ğŸ—‚ï¸ æ‰€æœ‰æ£€ç´¢ç»“æœ", "ğŸ’¬ ç”Ÿæˆæç¤ºè¯"])
    
    with tab1:
        if "step_by_step_analysis" in answer_dict:
            analysis = answer_dict["step_by_step_analysis"]
            if isinstance(analysis, list):
                for i, step in enumerate(analysis, 1):
                    st.markdown(f"**{i}.** {step}")
            else:
                st.write(analysis)
        else:
            st.info("æ— è¯¦ç»†åˆ†æ")
    
    with tab2:
        if "reasoning_summary" in answer_dict:
            st.write(answer_dict["reasoning_summary"])
        else:
            st.info("æ— æ¨ç†æ€»ç»“")
    
    with tab3:
        if "references" in answer_dict and answer_dict["references"]:
            refs = answer_dict["references"]
            
            # åŠ è½½æ–‡æ¡£æ˜ å°„
            doc_mapping = load_document_mapping("data/val_set/subset.csv")
            
            # ç»Ÿè®¡æ ¸å¿ƒé¡µé¢å’Œæ‰©å……é¡µé¢
            core_count = sum(1 for ref in refs if not ref.get('is_expanded', False))
            expanded_count = sum(1 for ref in refs if ref.get('is_expanded', False))
            
            st.markdown(f"### ğŸ“š LLMé€‰ç”¨çš„å‚è€ƒèµ„æ–™")
            
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ä¸Šæ¸¸æ‰©å……
            if "selected_groups" in answer_dict:
                # ä¸Šæ¸¸æ‰©å……æ¨¡å¼ï¼šæ˜¾ç¤ºç»„åˆä¿¡æ¯
                selected_groups = answer_dict["selected_groups"]
                st.caption(f"ğŸ”„ ä½¿ç”¨ä¸Šæ¸¸æ‰©å……æ¨¡å¼ | é€‰ç”¨ {len(selected_groups)} ä¸ªé¡µé¢ç»„åˆ | å…± {len(refs)} é¡µï¼ˆæ ¸å¿ƒé¡µ: {core_count}ï¼Œæ‰©å……é¡µ: {expanded_count}ï¼‰")
                
                # æ˜¾ç¤ºæ¯ä¸ªç»„åˆ
                for group_idx, group in enumerate(selected_groups, 1):
                    core_page = group['core_page']
                    core_score = group['core_score']
                    pages = group['pages']
                    
                    with st.expander(f"ğŸ“¦ ç»„åˆ {group_idx}: æ ¸å¿ƒé¡µ {core_page} (å¾—åˆ†: {core_score:.4f}) - åŒ…å« {len(pages)} é¡µ", expanded=(group_idx == 1)):
                        st.info(f"ğŸ“„ é¡µé¢èŒƒå›´: {pages[0]} - {pages[-1]} | æ ¸å¿ƒé¡µ: {core_page} | ç»„åˆå¾—åˆ†: {core_score:.4f}")
                        
                        # æ˜¾ç¤ºç»„åˆä¸­çš„é¡µé¢
                        group_refs = [r for r in refs if r['page_index'] in pages]
                        for ref in group_refs:
                            page_num = ref['page_index']
                            is_core = not ref.get('is_expanded', False)
                            doc_sha1 = ref.get('pdf_sha1', '')
                            
                            if is_core:
                                badge = 'â­ æ ¸å¿ƒé¡µ'
                                color = '#28a745'
                            else:
                                badge = 'ğŸ“ æ‰©å……é¡µ'
                                color = '#007bff'
                            
                            st.markdown(f'<span style="background-color: {color}; color: white; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;">{badge}</span> ç¬¬ {page_num} é¡µ', unsafe_allow_html=True)
            else:
                # ä¸‹æ¸¸æ‰©å……æ¨¡å¼ï¼šåŸæœ‰æ˜¾ç¤º
                st.caption(f"âœ… æ ¸å¿ƒå¼•ç”¨: {core_count}ä¸ª | ğŸ“ æ‰©å……é¡µé¢: {expanded_count}ä¸ªï¼ˆè‡ªåŠ¨æ·»åŠ ç›¸é‚»é¡µé¢ï¼‰")
            
            # æŒ‰æ–‡æ¡£åˆ†ç»„å¹¶æŒ‰é¡µç æ’åº
            from collections import defaultdict
            doc_groups = defaultdict(list)
            for ref in refs:
                sha1 = ref.get("pdf_sha1", "")
                page = ref.get("page_index", "N/A")
                chunk_text = ref.get("chunk_text", "")
                is_expanded = ref.get("is_expanded", False)
                group_id = ref.get("group_id")
                core_page = ref.get("core_page")
                group_score = ref.get("group_score")
                if sha1 and page != "N/A":
                    doc_groups[sha1].append({
                        'page': page,
                        'text': chunk_text,
                        'is_expanded': is_expanded,
                        'group_id': group_id,
                        'core_page': core_page,
                        'group_score': group_score
                    })
            
            # æŒ‰æ–‡æ¡£æ˜¾ç¤ºï¼Œæ¯ä¸ªæ–‡æ¡£å†…éƒ¨æŒ‰é¡µç æ’åº
            for doc_sha1, pages_data in doc_groups.items():
                # è·å–æ–‡æ¡£æ˜¾ç¤ºåç§°
                doc_info = doc_mapping.get(doc_sha1, {})
                doc_display_name = doc_info.get('display_name', doc_sha1)
                
                # æŒ‰é¡µç æ’åº
                pages_data.sort(key=lambda x: x['page'])
                
                # ç»Ÿè®¡è¯¥æ–‡æ¡£çš„æ ¸å¿ƒå’Œæ‰©å……é¡µé¢æ•°
                doc_core = sum(1 for p in pages_data if not p['is_expanded'])
                doc_expanded = sum(1 for p in pages_data if p['is_expanded'])
                
                # æ˜¾ç¤ºæ–‡æ¡£æ ‡é¢˜
                st.markdown(f"### ğŸ“„ {doc_display_name}")
                st.caption(f"æ ¸å¿ƒå¼•ç”¨: {doc_core}ä¸ª | æ‰©å……é¡µé¢: {doc_expanded}ä¸ª | å…± {len(pages_data)} é¡µ")
                
                # ä¸ºæ¯ä¸ªé¡µç æ˜¾ç¤ºå›¾ç‰‡å’Œæ–‡æœ¬
                for idx, page_data in enumerate(pages_data, 1):
                    page_num = page_data['page']
                    chunk_text = page_data['text']
                    is_expanded = page_data['is_expanded']
                    group_id = page_data.get('group_id')
                    core_page = page_data.get('core_page')
                    group_score = page_data.get('group_score')
                    
                    # æ ¹æ®æ˜¯å¦æ‰©å……é¡µé¢ä½¿ç”¨ä¸åŒçš„å›¾æ ‡å’Œæ ‡ç­¾
                    if is_expanded:
                        icon = "ğŸ“"
                        badge = '<span style="background-color: #007bff; color: white; padding: 2px 8px; border-radius: 3px; font-size: 0.85em;">ğŸ“ ç›¸é‚»æ‰©å……</span>'
                        if group_id is not None and core_page is not None:
                            group_info = f" | ç»„åˆ {group_id + 1}ï¼ˆæ ¸å¿ƒé¡µ: {core_page}ï¼‰"
                        else:
                            group_info = ""
                    else:
                        icon = "âœ…"
                        badge = '<span style="background-color: #28a745; color: white; padding: 2px 8px; border-radius: 3px; font-size: 0.85em; font-weight: bold;">âœ… LLMæ ¸å¿ƒå¼•ç”¨</span>'
                        if group_score is not None:
                            group_info = f" | ç»„åˆå¾—åˆ†: {group_score:.4f}"
                        else:
                            group_info = ""
                    
                    with st.expander(f"{icon} å¼•ç”¨ {idx}: ç¬¬ {page_num} é¡µ{group_info}", expanded=(idx == 1 and not is_expanded)):
                        # æ˜¾ç¤ºé¡µé¢ç±»å‹æ ‡ç­¾
                        st.markdown(badge, unsafe_allow_html=True)
                        st.markdown("")  # ç©ºè¡Œ
                        
                        # æ„å»ºPDFè·¯å¾„
                        pdf_path = Path("data/val_set/pdf_reports") / f"{doc_sha1}.pdf"
                        
                        if pdf_path.exists():
                            # æ˜¾ç¤ºPDFé¡µé¢å›¾ç‰‡
                            st.markdown(f"**ğŸ“– æ–‡æ¡£ç¬¬ {page_num} é¡µ:**")
                            
                            # æå–å¹¶æ˜¾ç¤ºPDFé¡µé¢å›¾ç‰‡
                            # æ³¨æ„ï¼špage_num æ˜¯ 1-basedï¼ˆç¬¬1é¡µã€ç¬¬2é¡µ...ï¼‰ï¼Œä½† PyMuPDF ä½¿ç”¨ 0-based ç´¢å¼•
                            page_image = get_pdf_page_image(str(pdf_path), page_num - 1)
                            if page_image:
                                st.image(page_image, use_container_width=True, caption=f"{doc_sha1} - é¡µç  {page_num}")
                            else:
                                st.warning("æ— æ³•åŠ è½½é¡µé¢å›¾ç‰‡")
                        else:
                            st.warning(f"æœªæ‰¾åˆ°PDFæ–‡ä»¶: {doc_sha1}.pdf")
                        
                        # æ˜¾ç¤ºæ–‡æœ¬æ‘˜å½•
                        if chunk_text:
                            st.markdown("**ğŸ“ ç›¸å…³æ–‡æœ¬æ‘˜å½•:**")
                            st.caption(chunk_text[:300] + "..." if len(chunk_text) > 300 else chunk_text)
        else:
            st.info("æ— å¼•ç”¨ä¿¡æ¯")
        
        # æ˜¾ç¤ºæºæ–‡æ¡£SHA1
        if "source_sha1" in answer_dict:
            st.markdown(f"**ğŸ“„ ä¸»è¦æ¥æº:** `{answer_dict['source_sha1']}`")
    
    with tab4:
        # æ˜¾ç¤ºæ‰€æœ‰æ£€ç´¢åˆ°çš„chunks
        if "all_retrieved_chunks" in answer_dict and answer_dict["all_retrieved_chunks"]:
            all_chunks = answer_dict["all_retrieved_chunks"]
            
            # åŠ è½½æ–‡æ¡£æ˜ å°„
            doc_mapping = load_document_mapping("data/val_set/subset.csv")
            
            st.markdown(f"### ğŸ” æ£€ç´¢åˆ° {len(all_chunks)} ä¸ªç›¸å…³æ–‡æœ¬å—")
            st.caption("âœ¨ æ ‡è®°ä¸º **LLMé€‰ç”¨** çš„æ˜¯æ¨¡å‹æœ€ç»ˆå¼•ç”¨çš„æ–‡æœ¬å—")
            
            # ç»Ÿè®¡ä¿¡æ¯
            llm_selected_count = sum(1 for chunk in all_chunks if chunk.get('selected_by_llm', False))
            
            # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨äº†é‡æ’åºï¼ˆå¦‚æœæœ‰combined_scoreåˆ™ä½¿ç”¨äº†é‡æ’åºï¼‰
            has_reranking = any(chunk.get('combined_score') is not None for chunk in all_chunks)
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("æ€»æ£€ç´¢æ•°", len(all_chunks))
            with col2:
                st.metric("LLMé€‰ç”¨", llm_selected_count, delta=f"{llm_selected_count}/{len(all_chunks)}")
            with col3:
                if has_reranking:
                    # è¿‡æ»¤æ‰ None å€¼ï¼Œåªè®¡ç®—æœ‰æ•ˆçš„ combined_score
                    valid_scores = [chunk.get('combined_score', 0) for chunk in all_chunks if chunk.get('combined_score') is not None]
                    avg_combined = sum(valid_scores) / len(valid_scores) if valid_scores else 0
                    st.metric("å¹³å‡ç»„åˆå¾—åˆ†", f"{avg_combined:.4f}")
                else:
                    # è¿‡æ»¤æ‰ None å€¼ï¼Œåªè®¡ç®—æœ‰æ•ˆçš„ vector_score
                    valid_scores = [chunk.get('vector_score', 0) for chunk in all_chunks if chunk.get('vector_score') is not None]
                    avg_vector = sum(valid_scores) / len(valid_scores) if valid_scores else 0
                    st.metric("å¹³å‡å‘é‡å¾—åˆ†", f"{avg_vector:.4f}")
            with col4:
                if has_reranking:
                    st.info("âœ… ä½¿ç”¨äº†LLMé‡æ’åº")
                else:
                    st.info("ğŸ“Š çº¯å‘é‡æ£€ç´¢")
            
            st.markdown("---")
            
            # æŒ‰å¾—åˆ†æ’åºæ˜¾ç¤º
            for chunk in all_chunks:
                rank = chunk.get('rank', 0)
                page = chunk.get('page', 'N/A')
                source_sha1 = chunk.get('source_sha1', '')
                text = chunk.get('text', '')
                vector_score = chunk.get('vector_score', 0.0)
                relevance_score = chunk.get('relevance_score', None)
                combined_score = chunk.get('combined_score', None)
                reasoning = chunk.get('reasoning', '')
                selected = chunk.get('selected_by_llm', False)
                is_expanded = chunk.get('is_expanded', False)  # æ˜¯å¦ä¸ºæ‰©å……çš„ç›¸é‚»é¡µé¢
                
                # è·å–æ–‡æ¡£æ˜¾ç¤ºåç§°
                doc_info = doc_mapping.get(source_sha1, {})
                doc_display_name = doc_info.get('display_name', source_sha1)
                
                # æ ¹æ®é¡µé¢çŠ¶æ€ï¼Œä½¿ç”¨ä¸åŒçš„æ ·å¼
                if selected:
                    icon = "â­"
                    badge = '<span style="background-color: #28a745; color: white; padding: 2px 8px; border-radius: 3px; font-size: 0.85em; font-weight: bold;">âœ… LLMæ ¸å¿ƒå¼•ç”¨</span>'
                    border_color = "#28a745"
                elif is_expanded:
                    icon = "ğŸ“"
                    badge = '<span style="background-color: #007bff; color: white; padding: 2px 8px; border-radius: 3px; font-size: 0.85em;">ğŸ“ ç›¸é‚»æ‰©å……</span>'
                    border_color = "#007bff"
                else:
                    icon = "ğŸ“„"
                    badge = '<span style="background-color: #6c757d; color: white; padding: 2px 8px; border-radius: 3px; font-size: 0.85em;">æœªé€‰ç”¨</span>'
                    border_color = "#dee2e6"
                
                # æ„å»ºæ˜¾ç¤ºçš„å¾—åˆ†ä¿¡æ¯
                if combined_score is not None:
                    score_display = f"ç»„åˆå¾—åˆ†: {combined_score:.4f}"
                else:
                    score_display = f"å‘é‡å¾—åˆ†: {vector_score:.4f}"
                
                # æ ‡è®°æ–‡æœ¬
                status_text = ""
                if selected:
                    status_text = "â­"
                elif is_expanded:
                    status_text = "ğŸ“"
                
                # æ˜¾ç¤ºæ¯ä¸ªchunk
                with st.expander(
                    f"{icon} æ’å #{rank} - {doc_display_name} ç¬¬{page}é¡µ - {score_display} {status_text}",
                    expanded=(rank == 1 and selected)
                ):
                    # é¡¶éƒ¨ä¿¡æ¯æ 
                    st.markdown(f"""
                    <div style="background-color: #f8f9fa; padding: 10px; border-radius: 5px; margin-bottom: 10px; border-left: 4px solid {border_color};">
                        <div style="display: flex; justify-content: space-between; align-items: center;">
                            <div>
                                <strong>ğŸ“ æ–‡æ¡£:</strong> {doc_display_name} | 
                                <strong>ğŸ“„ é¡µç :</strong> {page} |
                                <strong>ğŸ† æ’å:</strong> #{rank}
                            </div>
                            <div>
                                {badge}
                            </div>
                        </div>
                        <div style="margin-top: 8px; font-size: 0.9em;">
                            <strong>ğŸ”— SHA1:</strong> <code>{source_sha1}</code>
                        </div>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    # è¯¦ç»†å¾—åˆ†æ„æˆ
                    st.markdown("**ğŸ“Š å¾—åˆ†è¯¦æƒ…:**")
                    score_cols = st.columns(3)
                    with score_cols[0]:
                        st.metric("å‘é‡ç›¸ä¼¼åº¦", f"{vector_score:.6f}", help="åŸºäºåµŒå…¥å‘é‡çš„è¯­ä¹‰ç›¸ä¼¼åº¦å¾—åˆ†ï¼ˆè¶Šé«˜è¶Šç›¸ä¼¼ï¼‰")
                    with score_cols[1]:
                        if relevance_score is not None:
                            st.metric("LLMç›¸å…³æ€§", f"{relevance_score:.6f}", help="LLMåˆ¤æ–­çš„ç›¸å…³æ€§å¾—åˆ†ï¼ˆ0-1ä¹‹é—´ï¼‰")
                        else:
                            st.metric("LLMç›¸å…³æ€§", "æœªä½¿ç”¨", help="æœªå¯ç”¨LLMé‡æ’åº")
                    with score_cols[2]:
                        if combined_score is not None:
                            st.metric("ç»„åˆå¾—åˆ†", f"{combined_score:.6f}", help="å‘é‡å¾—åˆ†ä¸LLMå¾—åˆ†çš„åŠ æƒç»„åˆ")
                        else:
                            st.metric("ç»„åˆå¾—åˆ†", "æœªä½¿ç”¨", help="æœªå¯ç”¨LLMé‡æ’åº")
                    
                    # LLMæ¨ç†è¿‡ç¨‹ï¼ˆå¦‚æœæœ‰ï¼‰
                    if reasoning and selected:
                        st.markdown("**ğŸ¤” LLMæ¨ç†è¿‡ç¨‹:**")
                        st.info(reasoning)
                    
                    # PDFé¢„è§ˆï¼ˆå¦‚æœæ˜¯LLMé€‰ç”¨çš„ï¼‰
                    if selected:
                        pdf_path = Path("data/val_set/pdf_reports") / f"{source_sha1}.pdf"
                        if pdf_path.exists():
                            st.markdown("**ğŸ“– PDFé¡µé¢é¢„è§ˆ:**")
                            page_image = get_pdf_page_image(str(pdf_path), page - 1)
                            if page_image:
                                st.image(page_image, use_container_width=True, caption=f"{doc_display_name} - ç¬¬{page}é¡µ")
                    
                    # æ–‡æœ¬å†…å®¹
                    st.markdown("**ğŸ“ æ–‡æœ¬å†…å®¹:**")
                    st.text_area(
                        "æ–‡æœ¬",
                        text,
                        height=150,
                        key=f"chunk_{rank}_{page}_{source_sha1}",
                        label_visibility="collapsed"
                    )
        else:
            st.info("æ— æ£€ç´¢ç»“æœä¿¡æ¯")
    
    with tab5:
        # æ˜¾ç¤ºç”Ÿæˆé˜¶æ®µçš„æç¤ºè¯ä¿¡æ¯
        if "prompt_info" in answer_dict:
            prompt_info = answer_dict["prompt_info"]
            
            st.markdown("### ğŸ’¬ LLMç”Ÿæˆé˜¶æ®µçš„æç¤ºè¯")
            st.caption(f"ğŸ“‹ Schema: {prompt_info.get('schema', 'N/A')} | ğŸ¤– Model: {prompt_info.get('model', 'N/A')}")
            
            # é¡µé¢é€‰æ‹©ä¿¡æ¯ï¼ˆä¸¤é˜¶æ®µæµç¨‹ï¼‰
            if "page_selection" in prompt_info:
                page_selection = prompt_info["page_selection"]
                st.markdown("---")
                st.markdown("#### ğŸ¯ é¡µé¢é€‰æ‹©é˜¶æ®µï¼ˆä¸¤é˜¶æ®µæµç¨‹çš„ç¬¬ä¸€æ­¥ï¼‰")
                selected_pages = page_selection.get('selected_pages', [])
                selection_reasoning = page_selection.get('selection_reasoning', '')
                all_retrieval_context = page_selection.get('all_retrieval_context', '')
                
                col1, col2 = st.columns(2)
                with col1:
                    # è®¡ç®—æ‰€æœ‰æ£€ç´¢ç»“æœçš„æ•°é‡ï¼ˆé€šè¿‡åˆ†å‰² "---" æ¥ä¼°ç®—ï¼‰
                    total_retrieval_count = len(all_retrieval_context.split('---')) if all_retrieval_context else 0
                    st.metric("ğŸ“Š æ€»æ£€ç´¢æ•°é‡", total_retrieval_count if total_retrieval_count > 0 else "N/A")
                with col2:
                    st.metric("âœ… é€‰å®šé¡µé¢æ•°", len(selected_pages))
                
                if selected_pages:
                    st.markdown(f"**é€‰å®šçš„é¡µé¢ï¼š** {', '.join(map(str, selected_pages))}")
                
                if selection_reasoning:
                    st.markdown("**é€‰æ‹©ç†ç”±ï¼š**")
                    st.info(selection_reasoning)
                
                # æ˜¾ç¤ºæ‰€æœ‰æ£€ç´¢ç»“æœçš„ä¸Šä¸‹æ–‡ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
                if all_retrieval_context:
                    with st.expander("ğŸ“‹ æŸ¥çœ‹æ‰€æœ‰æ£€ç´¢ç»“æœçš„ä¸Šä¸‹æ–‡ï¼ˆé¡µé¢é€‰æ‹©é˜¶æ®µä½¿ç”¨ï¼‰", expanded=False):
                        st.caption(f"è¿™æ˜¯é¡µé¢é€‰æ‹©é˜¶æ®µçœ‹åˆ°çš„æ‰€æœ‰æ£€ç´¢ç»“æœï¼ˆå…± {len(all_retrieval_context.split('---'))} ä¸ªç»“æœï¼‰")
                        st.text_area(
                            "All Retrieval Context",
                            all_retrieval_context,
                            height=400,
                            key="all_retrieval_context_display",
                            label_visibility="collapsed"
                        )
            
            st.markdown("---")
            
            # System Prompt
            st.markdown("#### ğŸ“˜ System Promptï¼ˆç³»ç»Ÿæç¤ºè¯ï¼‰")
            st.text_area(
                "System Prompt",
                prompt_info.get('system_prompt', ''),
                height=300,
                key="system_prompt_display",
                label_visibility="collapsed"
            )
            
            st.markdown("---")
            
            # User Prompt
            st.markdown("#### ğŸ“ User Promptï¼ˆç”¨æˆ·æç¤ºè¯ï¼‰")
            st.caption("åŒ…å«å®Œæ•´çš„ä¸Šä¸‹æ–‡ä¿¡æ¯å’Œé—®é¢˜")
            st.text_area(
                "User Prompt",
                prompt_info.get('user_prompt', ''),
                height=400,
                key="user_prompt_display",
                label_visibility="collapsed"
            )
            
            st.markdown("---")
            
            # RAG Contextï¼ˆä»…ä¸Šä¸‹æ–‡éƒ¨åˆ†ï¼‰
            st.markdown("#### ğŸ“š RAG Contextï¼ˆæ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ï¼‰")
            if "page_selection" in prompt_info:
                st.caption("è¿™æ˜¯ä¼ é€’ç»™LLMçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»…åŒ…å«é¡µé¢é€‰æ‹©é˜¶æ®µé€‰å®šçš„é¡µé¢æ–‡æœ¬ï¼ˆä¸¤é˜¶æ®µæµç¨‹ï¼‰")
            else:
                st.caption("è¿™æ˜¯ä¼ é€’ç»™LLMçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ŒåŒ…å«æ‰€æœ‰æ£€ç´¢åˆ°çš„é¡µé¢æ–‡æœ¬")
            rag_context = prompt_info.get('rag_context', '')
            if rag_context:
                # è®¡ç®—ä¸Šä¸‹æ–‡é•¿åº¦
                context_length = len(rag_context)
                st.caption(f"ä¸Šä¸‹æ–‡é•¿åº¦: {context_length:,} å­—ç¬¦")
                st.text_area(
                    "RAG Context",
                    rag_context,
                    height=500,
                    key="rag_context_display",
                    label_visibility="collapsed"
                )
            else:
                st.info("æ— ä¸Šä¸‹æ–‡ä¿¡æ¯")
            
            st.markdown("---")
            
            # Question
            st.markdown("#### â“ Questionï¼ˆé—®é¢˜ï¼‰")
            st.caption("å‘é€ç»™LLMçš„å®Œæ•´é—®é¢˜ï¼ˆå¯èƒ½åŒ…å«å¯¹è¯å†å²ï¼‰")
            question = prompt_info.get('question', '')
            st.text_area(
                "Question",
                question,
                height=150,
                key="question_display",
                label_visibility="collapsed"
            )
            
            # å±•ç¤ºæ‰©å±•æ–‡æœ¬ï¼ˆHYDEå’ŒMulti-Queryï¼‰
            if "expansion_texts" in answer_dict:
                expansion_texts = answer_dict.get("expansion_texts", {})
                
                st.markdown("---")
                st.markdown("### ğŸ”„ æŸ¥è¯¢æ‰©å±•ç”Ÿæˆçš„æ–‡æœ¬")
                
                # HYDEæ‰©å±•æ–‡æœ¬
                if expansion_texts.get('hyde_text'):
                    st.markdown("#### ğŸ”® HYDE æ‰©å±•ï¼ˆå‡è®¾ç­”æ¡ˆï¼‰")
                    st.caption("HYDEæ–¹æ³•ç”Ÿæˆçš„å‡è®¾ç­”æ¡ˆæ–‡æœ¬ï¼Œç”¨äºå¢å¼ºæ£€ç´¢")
                    st.text_area(
                        "HYDE Text",
                        expansion_texts['hyde_text'],
                        height=200,
                        key="hyde_text_display",
                        label_visibility="collapsed"
                    )
                else:
                    st.markdown("#### ğŸ”® HYDE æ‰©å±•")
                    st.info("æœªå¯ç”¨HYDEæ‰©å±•")
                
                st.markdown("---")
                
                # Multi-Queryæ‰©å±•æ–‡æœ¬
                multi_query_texts = expansion_texts.get('multi_query_texts', [])
                mq_methods_used = expansion_texts.get('multi_query_methods', {})
                
                st.markdown("#### ğŸ”„ Multi-Query æ‰©å±•ï¼ˆæ‰©å±•æŸ¥è¯¢ï¼‰")
                
                # æ£€æŸ¥æ˜¯å¦å¯ç”¨äº† Multi-Query
                if not any(mq_methods_used.values()):
                    st.info("âšª æœªå¯ç”¨ Multi-Query æ‰©å±•")
                elif multi_query_texts:
                    st.caption(f"Multi-Queryæ–¹æ³•ç”Ÿæˆçš„æ‰©å±•æŸ¥è¯¢ï¼Œå…± {len(multi_query_texts)} ä¸ª")
                    
                    for idx, mq_item in enumerate(multi_query_texts, 1):
                        method_id = mq_item.get('method_id', idx)
                        query_text = mq_item.get('query', '')
                        
                        method_names = {
                            1: "åè¯è§£é‡Š",
                            2: "æŒ‡æ ‡æ‹†åˆ†",
                            3: "æƒ…æ™¯å˜ä½“"
                        }
                        method_name = method_names.get(method_id, f"æ–¹æ³•{method_id}")
                        
                        with st.expander(f"ğŸ“ {method_name} (æ–¹æ³• {method_id})", expanded=(idx == 1)):
                            st.text_area(
                                f"æ‰©å±•æŸ¥è¯¢ {idx}",
                                query_text,
                                height=100,
                                key=f"multi_query_{method_id}_{idx}",
                                label_visibility="collapsed"
                            )
                else:
                    # Multi-Query å·²å¯ç”¨ä½†æ²¡æœ‰ç”Ÿæˆæ‰©å±•æŸ¥è¯¢ï¼ˆLLM åˆ¤æ–­é—®é¢˜å·²è¶³å¤Ÿæ¸…æ™°ï¼‰
                    st.info("âœ… Multi-Query å·²å¯ç”¨ï¼Œä½† LLM åˆ¤æ–­å½“å‰é—®é¢˜å·²è¶³å¤Ÿæ¸…æ™°ï¼Œæ— éœ€æ‰©å±•æŸ¥è¯¢")

                # æ˜¾ç¤ºå¯ç”¨çš„ Multi-Query æ–¹æ³•
                if any(mq_methods_used.values()):
                    label_map = {
                        'synonym': "åè¯è§£é‡Š",
                        'subquestion': "æŒ‡æ ‡æ‹†åˆ†",
                        'variant': "æƒ…æ™¯å˜ä½“"
                    }
                    enabled_labels = [label_map[k] for k, v in mq_methods_used.items() if v]
                    if enabled_labels:
                        st.caption("æœ¬æ¬¡å¯ç”¨çš„æ‰©å±•æ–¹å¼ï¼š" + "ã€".join(enabled_labels))
                
                # æ˜¾ç¤ºåè¯è§£é‡Šï¼ˆGlossaryï¼‰
                glossary_context = expansion_texts.get('glossary_context')
                if glossary_context:
                    st.markdown("---")
                    st.markdown("##### ğŸ“– Multi-Query ä½¿ç”¨çš„è´¢åŠ¡åè¯è§£é‡Š")
                    st.text_area(
                        "Glossary Context",
                        glossary_context,
                        height=220,
                        key="multi_query_glossary_display",
                        label_visibility="collapsed"
                    )
        else:
            st.info("âš ï¸ æç¤ºè¯ä¿¡æ¯ä¸å¯ç”¨ï¼ˆå¯èƒ½æ˜¯æ—§ç‰ˆæœ¬çš„ç­”æ¡ˆï¼‰")

def save_history():
    """ä¿å­˜é—®ç­”å†å²"""
    if st.session_state.history:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"qa_history_{timestamp}.json"
        
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(st.session_state.history, f, ensure_ascii=False, indent=2)
        
        return filename
    return None

def prepare_conversation_history(max_turns: int) -> list:
    """
    å‡†å¤‡å¯¹è¯å†å²ç”¨äºå¤šè½®å¯¹è¯
    
    Args:
        max_turns: æœ€å¤šä¿ç•™çš„å†å²è½®æ•°
    
    Returns:
        æ ¼å¼åŒ–çš„å†å²å¯¹è¯åˆ—è¡¨ï¼ŒåŒ…å«é—®é¢˜å’Œç®€åŒ–çš„ç­”æ¡ˆ
    """
    if not st.session_state.history or not st.session_state.enable_multi_turn:
        return None
    
    # è·å–æœ€è¿‘çš„Nè½®å¯¹è¯
    recent_history = st.session_state.history[-max_turns:] if len(st.session_state.history) > max_turns else st.session_state.history
    
    # æ ¼å¼åŒ–å†å²è®°å½•ï¼ˆæå–å…³é”®ä¿¡æ¯ï¼‰
    formatted_history = []
    for record in recent_history:
        question = record.get('question', '')
        answer_dict = record.get('answer', {})
        
        # æå–å…³é”®ç­”æ¡ˆä¿¡æ¯ï¼ˆä¼˜å…ˆä½¿ç”¨æ¨ç†æ‘˜è¦ï¼Œå…¶æ¬¡ä½¿ç”¨æœ€ç»ˆç­”æ¡ˆï¼‰
        if 'reasoning_summary' in answer_dict and answer_dict['reasoning_summary']:
            answer = answer_dict['reasoning_summary']
        elif 'final_answer' in answer_dict:
            answer = str(answer_dict['final_answer'])
        else:
            answer = 'N/A'
        
        formatted_history.append({
            'question': question,
            'answer': answer
        })
    
    return formatted_history

# ==================== ä¾§è¾¹æ é…ç½® ====================
with st.sidebar:
    st.title("âš™ï¸ ç³»ç»Ÿé…ç½®")
    
    if 'config' not in st.session_state:
        st.session_state.config = {
            'api_provider': 'qwen',
            'answering_model': 'qwen-max',
            'top_n_retrieval': 10,
            'use_hyde': True,
            'use_multi_query': True,
            'llm_reranking': True,
            'rerank_sample_size': 50,
            'expand_upstream': True,
            'expand_top_k': 5,
            'expand_context_size': 1,
            'parallel_requests': 4,
            'multi_query_methods': {
                'synonym': True,
                'subquestion': False,
                'variant': False
            }
        }
    
    flow_steps = [
        {"id": "overview", "label": "æµç¨‹æ¦‚è§ˆ", "icon": "ğŸ"},
        {"id": "model", "label": "æ¨¡å‹é…ç½®", "icon": "ğŸ¤–"},
        {"id": "retrieval", "label": "åŸºç¡€æ£€ç´¢", "icon": "âš™ï¸"},
        {"id": "enhancement", "label": "æ£€ç´¢å¢å¼º", "icon": "ğŸš€"},
        {"id": "rerank", "label": "LLMé‡æ’åº", "icon": "ğŸ¯"},
        {"id": "expansion", "label": "ä¸Šæ¸¸æ‰©å……", "icon": "ğŸ”„"},
        {"id": "data", "label": "æ•°æ®ä¸å¤šè½®", "icon": "ğŸ“…"},
    ]
    flow_options = [step["id"] for step in flow_steps]
    current_step = st.session_state.get("flow_step_selector", flow_options[0])
    selected_step = st.radio(
        "æµç¨‹èŠ‚ç‚¹",
        options=flow_options,
        index=flow_options.index(current_step),
        format_func=lambda x: next(step["label"] for step in flow_steps if step["id"] == x),
        key="flow_step_selector",
        label_visibility="collapsed"
    )
    
    st.markdown("""
    <style>
    .flow-container {display:flex;flex-direction:column;gap:6px;margin-bottom:12px;}
    .flow-step {border:1px solid #e1e6ef;border-radius:10px;padding:6px 12px;background:#f8f9fc;color:#495057;font-weight:500;display:flex;align-items:center;gap:8px;}
    .flow-step.active {background:linear-gradient(90deg,#0d6efd,#6ea8fe);color:#fff;border-color:#0d6efd;box-shadow:0 4px 10px rgba(13,110,253,0.2);}
    .flow-arrow {text-align:center;color:#adb5bd;}
    </style>
    """, unsafe_allow_html=True)
    
    flow_html = "<div class='flow-container'>"
    for idx, step in enumerate(flow_steps):
        active_class = "active" if step["id"] == selected_step else ""
        flow_html += f"<div class='flow-step {active_class}'>{step['icon']} {step['label']}</div>"
        if idx < len(flow_steps) - 1:
            flow_html += "<div class='flow-arrow'>â†“</div>"
    flow_html += "</div>"
    st.markdown(flow_html, unsafe_allow_html=True)
    
    config_defaults = st.session_state.config
    if 'multi_query_methods' not in config_defaults:
        config_defaults['multi_query_methods'] = {
            'synonym': True,
            'subquestion': False,
            'variant': False
        }
    multi_query_methods_defaults = config_defaults['multi_query_methods']
    selected_multi_query_methods = multi_query_methods_defaults.copy()
    api_provider = config_defaults.get('api_provider', 'qwen')
    answering_model = config_defaults.get('answering_model', 'qwen-max')
    top_n_retrieval = config_defaults.get('top_n_retrieval', 10)
    use_hyde = config_defaults.get('use_hyde', True)
    use_multi_query = config_defaults.get('use_multi_query', True)
    llm_reranking = config_defaults.get('llm_reranking', True)
    rerank_sample_size = config_defaults.get('rerank_sample_size', 50)
    expand_upstream = config_defaults.get('expand_upstream', True)
    expand_top_k = config_defaults.get('expand_top_k', 5)
    expand_context_size = config_defaults.get('expand_context_size', 1)
    selected_years = st.session_state.get("selected_years", []) or []
    parallel_requests = config_defaults.get('parallel_requests', 4)
    
    with st.expander("âœ¨ æµç¨‹æ¦‚è§ˆ Â· æ¨èé…ç½®", expanded=(selected_step == "overview")):
        st.markdown("""
        **ğŸ¯ æ¨èè®¾ç½®ï¼ˆå·²åº”ç”¨ï¼‰**
        
        âœ… æ£€ç´¢æ•°é‡ï¼š10  
        âœ… HYDEï¼šå¼€å¯  
        âœ… Multi-Queryï¼šå¼€å¯  
        âœ… LLMé‡æ’åºï¼šå¼€å¯  
        âœ… åˆå§‹å¬å›ï¼š50  
        âœ… ä¸Šæ¸¸æ‰©å……ï¼šå¼€å¯  
        âœ… æ ¸å¿ƒé¡µé¢ï¼š5  
        âœ… æ‰©å……é¡µæ•°ï¼šä¸Šä¸‹å„1é¡µ  
        âœ… å¤šè½®å¯¹è¯ï¼šå…³é—­  
        
        ğŸ’¡ ä½¿ç”¨ä¸Šæ–¹æµç¨‹å›¾å¯å¿«é€Ÿè·³è½¬è‡³å¯¹åº”æ­¥éª¤è¿›è¡Œé…ç½®
        """)
    
    with st.expander("ğŸ¤– æ¨¡å‹é…ç½®", expanded=(selected_step == "model")):
        api_provider = st.selectbox(
            "API æä¾›å•†",
            options=['qwen', 'openai', 'gemini'],
            index=['qwen', 'openai', 'gemini'].index(api_provider) if api_provider in ['qwen', 'openai', 'gemini'] else 0,
            help="é€‰æ‹©å¤§è¯­è¨€æ¨¡å‹APIæä¾›å•†"
        )
        
        if api_provider == 'qwen':
            model_options = ['qwen-max', 'qwen-plus', 'qwen-turbo']
        elif api_provider == 'openai':
            model_options = ['gpt-4o', 'gpt-4o-mini', 'gpt-4-turbo']
        else:
            model_options = ['gemini-1.5-pro', 'gemini-1.5-flash']
    
    answering_model = st.selectbox(
        "å›ç­”æ¨¡å‹",
        options=model_options,
            index=model_options.index(answering_model) if answering_model in model_options else 0,
        help="ç”¨äºç”Ÿæˆç­”æ¡ˆçš„æ¨¡å‹"
    )
    
    with st.expander("âš™ï¸ åŸºç¡€æ£€ç´¢", expanded=(selected_step == "retrieval")):
        top_n_retrieval = st.slider(
            "ğŸ“Š æœ€ç»ˆæ£€ç´¢æ•°é‡",
            min_value=5,
            max_value=30,
            value=top_n_retrieval,
            step=5,
            help="ç»è¿‡é‡æ’åºåæœ€ç»ˆä¼ é€’ç»™LLMçš„æ–‡æ¡£å—æ•°é‡"
        )
    
    with st.expander("ğŸš€ æ£€ç´¢å¢å¼º", expanded=(selected_step == "enhancement")):
        use_hyde = st.checkbox(
            "âœ¨ HYDEï¼ˆå‡è®¾æ€§æ–‡æ¡£æ‰©å±•ï¼‰",
            value=use_hyde,
            help="ç”Ÿæˆå‡è®¾æ€§ç­”æ¡ˆè¾…åŠ©æ£€ç´¢ï¼Œæé«˜è¯­ä¹‰åŒ¹é…åº¦",
            key="hyde_checkbox"
        )
        use_multi_query = st.checkbox(
            "ğŸ”„ Multi-Queryï¼ˆå¤šæŸ¥è¯¢æ‰©å±•ï¼‰",
            value=use_multi_query,
            help="ç”Ÿæˆå¤šä¸ªç›¸å…³æŸ¥è¯¢å¹¶è¡Œæ£€ç´¢ï¼Œæé«˜å¬å›ç‡",
            key="multiquery_checkbox"
        )
        if use_multi_query:
            st.markdown("#### ğŸ§© Multi-Query æ‰©å±•æ–¹å¼")
            col_syn, col_sub, col_var = st.columns(3)
            synonym_enabled = col_syn.checkbox(
                "åè¯è§£é‡Š",
                value=multi_query_methods_defaults.get('synonym', True),
                help="ä¸ºè´¢åŠ¡åè¯è¡¥å……åŒä¹‰è¯ã€å®šä¹‰ã€è®¡ç®—æ–¹å¼",
                key=f"multiquery_synonym_checkbox_{selected_step}"
            )
            subquestion_enabled = col_sub.checkbox(
                "æŒ‡æ ‡æ‹†åˆ†",
                value=multi_query_methods_defaults.get('subquestion', False),
                help="æŒ‰æŒ‡æ ‡/æ—¶é—´æ‹†åˆ†å¤šæ¡å­é—®é¢˜",
                key=f"multiquery_sub_checkbox_{selected_step}"
            )
            variant_enabled = col_var.checkbox(
                "æƒ…æ™¯å˜ä½“",
                value=multi_query_methods_defaults.get('variant', False),
                help="åœ¨é—®é¢˜å¼€æ”¾æˆ–æ¨¡ç³Šæ—¶ç”Ÿæˆä¸åŒè§†è§’çš„æé—®",
                key=f"multiquery_variant_checkbox_{selected_step}"
            )
            selected_multi_query_methods = {
                'synonym': synonym_enabled,
                'subquestion': subquestion_enabled,
                'variant': variant_enabled
            }
            if not any(selected_multi_query_methods.values()):
                st.warning("âš ï¸ æ‰€æœ‰æ‰©å±•æ–¹å¼å‡å·²å…³é—­ï¼Œå°†ä»…ä½¿ç”¨åŸé—®é¢˜è¿›è¡Œæ£€ç´¢")
        else:
            selected_multi_query_methods = {
                'synonym': False,
                'subquestion': False,
                'variant': False
            }
    
    with st.expander("ğŸ¯ LLM é‡æ’åº", expanded=(selected_step == "rerank")):
        llm_reranking = st.checkbox(
            "ğŸ§  å¯ç”¨ LLM é‡æ’åº",
            value=llm_reranking,
            help="ä½¿ç”¨LLMè¯„ä¼°ç›¸å…³æ€§å¹¶é‡æ–°æ’åºï¼Œæ˜¾è‘—æé«˜ç²¾ç¡®åº¦",
            key="llm_rerank_checkbox"
        )
        
        if llm_reranking:
            rerank_sample_size = st.slider(
                "ğŸ” åˆå§‹å¬å›æ•°é‡",
                min_value=20,
                max_value=100,
                value=rerank_sample_size,
                step=10,
                help="LLMé‡æ’åºå‰å…ˆå¬å›çš„å€™é€‰chunksæ•°é‡ï¼ˆè¶Šå¤§è¶Šå…¨é¢ä½†è¶Šæ…¢ï¼‰"
            )
            st.success(f"âœ… é‡æ’åºæµç¨‹ï¼šå¬å› **{rerank_sample_size}** â†’ LLMé‡æ’ â†’ è¿”å› **{top_n_retrieval}**")
        else:
            rerank_sample_size = 10
    
    with st.expander("ğŸ”„ ä¸Šæ¸¸æ‰©å……", expanded=(selected_step == "expansion")):
        if llm_reranking:
            expand_upstream = st.checkbox(
                "ğŸ“ˆ å¯ç”¨ä¸Šæ¸¸æ‰©å……",
                value=expand_upstream,
                help="åœ¨ç­”æ¡ˆç”Ÿæˆå‰æ‰©å……é¡µé¢ç»„åˆï¼Œè®©LLMåŸºäºæ›´å®Œæ•´çš„ä¸Šä¸‹æ–‡ç”Ÿæˆé«˜è´¨é‡ç­”æ¡ˆ",
                key="upstream_checkbox"
            )
            if expand_upstream:
                col1, col2 = st.columns(2)
                with col1:
                    expand_top_k = st.slider(
                        "æ ¸å¿ƒé¡µé¢æ•°",
                        min_value=3,
                        max_value=10,
                        value=expand_top_k,
                        help="é€‰å–é‡æ’åºåçš„å‰Kä¸ªé¡µé¢ä½œä¸ºæ ¸å¿ƒ"
                    )
                with col2:
                    expand_context_size = st.slider(
                        "ä¸Šä¸‹æ‰©å……é¡µæ•°",
                        min_value=1,
                        max_value=3,
                        value=expand_context_size,
                        help="æ¯ä¸ªæ ¸å¿ƒé¡µé¢ä¸Šä¸‹å„æ‰©å……Né¡µ"
                    )
                estimated_pages = expand_top_k * (2 * expand_context_size + 1)
                st.info(f"ğŸ“Š é¢„è®¡ã€{estimated_pages}ã€‘é¡µä¸Šä¸‹æ–‡ï¼Œå»é‡åçº¦ 20-40 é¡µ")
                estimated_tokens = estimated_pages * 800
                if estimated_tokens > 25000:
                    st.error(f"ğŸš¨ Token é¢„ä¼° {estimated_tokens:,}ï¼Œå¯èƒ½è¶…é™ï¼Œå»ºè®®é™ä½æ‰©å……èŒƒå›´")
                elif estimated_tokens > 15000:
                    st.warning(f"âš ï¸ Token é¢„ä¼° {estimated_tokens:,}ï¼Œå“åº”æ—¶é—´å¯èƒ½è¾ƒé•¿")
                else:
                    st.success(f"âœ… Token é¢„ä¼° {estimated_tokens:,}ï¼Œå¤„äºå®‰å…¨èŒƒå›´")
            else:
                expand_top_k = 5
                expand_context_size = 1
                st.info("ğŸ’¡ å½“å‰ä½¿ç”¨ä¸‹æ¸¸æ‰©å……ï¼Œä»…åœ¨ç­”æ¡ˆç”Ÿæˆåè¡¥å……å¼•ç”¨")
        else:
            expand_upstream = False
            expand_top_k = 5
            expand_context_size = 1
            st.info("âš ï¸ è¯·å…ˆå¯ç”¨ LLM é‡æ’åºä»¥ä½¿ç”¨ä¸Šæ¸¸æ‰©å……")
    
    with st.expander("ğŸ“… æ•°æ®ä¸å¤šè½®å¯¹è¯", expanded=(selected_step == "data")):
        if st.session_state.initialized:
            subset_path = Path("data/val_set/subset.csv")
            company_name = st.session_state.get("company_name", "é‡‘ç›˜ç§‘æŠ€")
            available_years = get_available_years(str(subset_path), company_name)
            if available_years:
                st.info(f"ğŸ’¡ å¯ç”¨å¹´ä»½: {', '.join(map(str, available_years))}")
                selected_years = st.multiselect(
                    "é€‰æ‹©ç‰¹å®šå¹´ä»½æ•°æ®ï¼ˆç•™ç©º=æ‰€æœ‰å¹´ä»½ï¼‰",
                    options=available_years,
                    default=selected_years,
                    help="é€‰æ‹©ç‰¹å®šå¹´ä»½è¿›è¡Œæ£€ç´¢ï¼›ä¸é€‰åˆ™é»˜è®¤å…¨é‡",
                    key="year_selector"
                )
                st.session_state.selected_years = selected_years if selected_years else None
            else:
                st.warning("âš ï¸ æ— å¯ç”¨å¹´ä»½ï¼Œé»˜è®¤åœ¨æ‰€æœ‰å¹´ä»½ä¸­æ£€ç´¢")
                st.session_state.selected_years = None
        else:
            st.info("â„¹ï¸ ç³»ç»Ÿå°šæœªåˆå§‹åŒ–ï¼Œæš‚æ— æ³•è¯»å–å¹´ä»½ä¿¡æ¯")
        st.session_state.selected_years = None
    
    enable_multi_turn = st.checkbox(
        "å¯ç”¨å¤šè½®å¯¹è¯",
            value=st.session_state.enable_multi_turn,
            help="å¯ç”¨åè®°ä½ä¸Šä¸‹æ–‡ï¼Œå¯èƒ½å¢åŠ tokenæ¶ˆè€—",
        key="multi_turn_checkbox"
    )
    st.session_state.enable_multi_turn = enable_multi_turn
    if enable_multi_turn:
        context_turns = st.slider(
            "ä¿ç•™å¯¹è¯è½®æ•°",
            min_value=1,
            max_value=10,
            value=st.session_state.context_turns,
            step=1,
            help="è®¾ç½®ä¿ç•™å¤šå°‘è½®å†å²å¯¹è¯ä½œä¸ºä¸Šä¸‹æ–‡",
            key="context_turns_slider"
        )
        st.session_state.context_turns = context_turns
        st.info(f"ğŸ’¡ å½“å‰ä¿ç•™æœ€è¿‘ **{context_turns}** è½®å¯¹è¯ä½œä¸ºä¸Šä¸‹æ–‡")
    else:
        st.warning("âš ï¸ å¤šè½®å¯¹è¯å·²å…³é—­ï¼Œæ¯æ¬¡é—®ç­”ç›¸äº’ç‹¬ç«‹")
    
    # æ£€æµ‹é…ç½®å˜åŒ–
    new_config = {
        'api_provider': api_provider,
        'answering_model': answering_model,
        'top_n_retrieval': top_n_retrieval,
        'use_hyde': use_hyde,
        'use_multi_query': use_multi_query,
        'llm_reranking': llm_reranking,
        'rerank_sample_size': rerank_sample_size,
        'expand_upstream': expand_upstream,
        'expand_top_k': expand_top_k,
        'expand_context_size': expand_context_size,
        'parallel_requests': parallel_requests,
        'multi_query_methods': selected_multi_query_methods
    }
    
    # å¦‚æœé…ç½®æ”¹å˜ä¸”ç³»ç»Ÿå·²åˆå§‹åŒ–ï¼Œéœ€è¦é‡æ–°åˆå§‹åŒ–
    if st.session_state.initialized and st.session_state.config != new_config:
        st.session_state.initialized = False
        st.session_state.processor = None
        st.warning("âš ï¸ æ£€æµ‹åˆ°é…ç½®å˜åŒ–ï¼Œç³»ç»Ÿå°†åœ¨ä¸‹æ¬¡æŸ¥è¯¢æ—¶é‡æ–°åˆå§‹åŒ–")
    
    # æ›´æ–°é…ç½®
    st.session_state.config = new_config
    
    st.markdown("---")
    st.subheader("ğŸ“Š ç³»ç»ŸçŠ¶æ€")
    
    if st.session_state.initialized:
        st.success("âœ… ç³»ç»Ÿå·²åˆå§‹åŒ–")
        st.info(f"ğŸ¢ å…¬å¸: {st.session_state.company_name}")
        st.info(f"ğŸ’¬ å†å²é—®ç­”: {len(st.session_state.history)} æ¡")
    else:
        st.warning("âš ï¸ ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    # åˆå§‹åŒ–æŒ‰é’®
    if st.button("ğŸ”„ é‡æ–°åˆå§‹åŒ–ç³»ç»Ÿ", use_container_width=True):
        st.session_state.initialized = False
        st.session_state.processor = None
        st.rerun()
    
    # ä¿å­˜å†å²æŒ‰é’®
    if st.button("ğŸ’¾ ä¿å­˜é—®ç­”å†å²", use_container_width=True):
        filename = save_history()
        if filename:
            st.success(f"âœ… å†å²å·²ä¿å­˜åˆ° {filename}")
        else:
            st.warning("âš ï¸ æ— å†å²è®°å½•å¯ä¿å­˜")
    
    # æ¸…ç©ºå†å²æŒ‰é’®
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯å†å²", use_container_width=True, type="secondary"):
        if st.session_state.history:
            st.session_state.history = []
            st.success("âœ… å¯¹è¯å†å²å·²æ¸…ç©º")
            st.rerun()
        else:
            st.info("â„¹ï¸ å½“å‰æ— å†å²è®°å½•")
    
    # æ¸…ç©ºå†å²æŒ‰é’®
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå†å²", use_container_width=True):
        st.session_state.history = []
        st.success("âœ… å†å²å·²æ¸…ç©º")
        st.rerun()
    
    st.markdown("---")
    st.markdown("### ğŸ“Š æ‰¹é‡è¯„ä¼°")
    
    # æ‰¹é‡è¯„ä¼°é…ç½®
    with st.expander("âš™ï¸ è¯„ä¼°é…ç½®ï¼ˆå¯é€‰ï¼‰", expanded=False):
        st.markdown("#### ğŸ”§ è¯„ä¼°æ—¶ä½¿ç”¨çš„é…ç½®")
        st.info("ğŸ’¡ å¦‚æœä¸ä¿®æ”¹ï¼Œå°†ä½¿ç”¨ä¸Šæ–¹æµç¨‹é…ç½®ä¸­çš„å½“å‰è®¾ç½®")
        
        eval_col1, eval_col2 = st.columns(2)
        
        with eval_col1:
            st.markdown("##### ğŸš€ æ£€ç´¢å¢å¼º")
            eval_use_hyde = st.checkbox(
                "å¯ç”¨ HYDE",
                value=config_defaults.get('use_hyde', True),
                help="ç”Ÿæˆå‡è®¾æ€§ç­”æ¡ˆè¾…åŠ©æ£€ç´¢",
                key="eval_use_hyde"
            )
            eval_use_multi_query = st.checkbox(
                "å¯ç”¨ Multi-Query",
                value=config_defaults.get('use_multi_query', True),
                help="ç”Ÿæˆå¤šä¸ªç›¸å…³æŸ¥è¯¢å¹¶è¡Œæ£€ç´¢",
                key="eval_use_multi_query"
            )
            
            if eval_use_multi_query:
                st.markdown("**Multi-Query æ–¹æ³•ï¼š**")
                eval_mq_synonym = st.checkbox(
                    "åè¯è§£é‡Š",
                    value=config_defaults.get('multi_query_methods', {}).get('synonym', True),
                    help="ä¸ºè´¢åŠ¡åè¯è¡¥å……å®šä¹‰ã€è¿‘ä¹‰è¯ã€è®¡ç®—æ–¹æ³•",
                    key="eval_mq_synonym"
                )
                eval_mq_subquestion = st.checkbox(
                    "æŒ‡æ ‡æ‹†åˆ†",
                    value=config_defaults.get('multi_query_methods', {}).get('subquestion', False),
                    help="æŒ‰æŒ‡æ ‡/æ—¶é—´æ‹†åˆ†å­é—®é¢˜",
                    key="eval_mq_subquestion"
                )
                eval_mq_variant = st.checkbox(
                    "æƒ…æ™¯å˜ä½“",
                    value=config_defaults.get('multi_query_methods', {}).get('variant', False),
                    help="ç”Ÿæˆä¸åŒè§’åº¦çš„æé—®",
                    key="eval_mq_variant"
                )
        
        with eval_col2:
            st.markdown("##### ğŸ¯ é‡æ’åºä¸æ‰©å……")
            eval_llm_reranking = st.checkbox(
                "å¯ç”¨ LLM é‡æ’åº",
                value=config_defaults.get('llm_reranking', True),
                help="ä½¿ç”¨LLMå¯¹æ£€ç´¢ç»“æœè¿›è¡Œæ™ºèƒ½é‡æ’åº",
                key="eval_llm_reranking"
            )
            
            if eval_llm_reranking:
                eval_rerank_sample_size = st.number_input(
                    "é‡æ’åºæ ·æœ¬æ•°",
                    min_value=10,
                    max_value=100,
                    value=config_defaults.get('rerank_sample_size', 20),
                    step=10,
                    help="LLMé‡æ’åºæ—¶å¤„ç†çš„æ ·æœ¬æ•°é‡",
                    key="eval_rerank_sample_size"
                )
            else:
                eval_rerank_sample_size = 20
            
            eval_expand_upstream = st.checkbox(
                "å¯ç”¨ä¸Šä¸‹æ¸¸æ‰©å……",
                value=config_defaults.get('expand_upstream', True),
                help="æ‰©å……æ£€ç´¢ç»“æœçš„ä¸Šä¸‹æ–‡é¡µé¢",
                key="eval_expand_upstream"
            )
            
            if eval_expand_upstream:
                eval_expand_top_k = st.number_input(
                    "æ‰©å…… top-k",
                    min_value=1,
                    max_value=20,
                    value=config_defaults.get('expand_top_k', 5),
                    step=1,
                    help="å¯¹å‰kä¸ªæ£€ç´¢ç»“æœè¿›è¡Œä¸Šä¸‹æ¸¸æ‰©å……",
                    key="eval_expand_top_k"
                )
                eval_expand_context_size = st.number_input(
                    "æ‰©å……å¤§å°",
                    min_value=1,
                    max_value=5,
                    value=config_defaults.get('expand_context_size', 1),
                    step=1,
                    help="å‘ä¸Šå’Œå‘ä¸‹å„æ‰©å……çš„é¡µé¢æ•°",
                    key="eval_expand_context_size"
                )
            else:
                eval_expand_top_k = 5
                eval_expand_context_size = 1
            
            st.markdown("##### ğŸ“Š æ£€ç´¢å‚æ•°")
            eval_top_n = st.number_input(
                "æœ€ç»ˆæ£€ç´¢æ•°é‡",
                min_value=5,
                max_value=50,
                value=config_defaults.get('top_n_retrieval', 10),
                step=5,
                help="æœ€ç»ˆè¿”å›çš„æ£€ç´¢ç»“æœæ•°é‡",
                key="eval_top_n"
            )
        
        # åº”ç”¨è¯„ä¼°é…ç½®æŒ‰é’®
        if st.button("âœ… åº”ç”¨æ­¤é…ç½®åˆ°è¯„ä¼°", use_container_width=True):
            st.session_state.eval_config = {
                'use_hyde': eval_use_hyde,
                'use_multi_query': eval_use_multi_query,
                'multi_query_methods': {
                    'synonym': eval_mq_synonym if eval_use_multi_query else False,
                    'subquestion': eval_mq_subquestion if eval_use_multi_query else False,
                    'variant': eval_mq_variant if eval_use_multi_query else False
                },
                'llm_reranking': eval_llm_reranking,
                'rerank_sample_size': eval_rerank_sample_size,
                'expand_upstream': eval_expand_upstream,
                'expand_top_k': eval_expand_top_k,
                'expand_context_size': eval_expand_context_size,
                'top_n_retrieval': eval_top_n
            }
            st.success("âœ… è¯„ä¼°é…ç½®å·²åº”ç”¨ï¼ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å¼€å§‹è¯„ä¼°")
    
    if st.button("ğŸš€ ä¸€é”®è¯„ä¼°æ‰€æœ‰é—®é¢˜", use_container_width=True, type="primary"):
        st.session_state.evaluating = True
        st.rerun()
    
    parallel_requests = st.slider(
        "ğŸ§µ æ‰¹é‡è¯„ä¼°å¹¶å‘æ•°",
        min_value=1,
        max_value=16,
        value=config_defaults.get('parallel_requests', 4),
        step=1,
        help="è®¾ç½®ä¸€é”®è¯„ä¼°è¿è¡Œæ—¶ä½¿ç”¨çš„å¹¶è¡Œçº¿ç¨‹æ•°ï¼ˆæ•°å€¼è¶Šå¤§é€Ÿåº¦è¶Šå¿«ï¼Œä½†å ç”¨èµ„æºæ›´å¤šï¼‰",
        key="parallel_requests_slider"
    )
    st.session_state.config['parallel_requests'] = parallel_requests
    
    st.markdown("---")
    st.markdown("### ğŸ“– ä½¿ç”¨è¯´æ˜")
    st.markdown("""
    1. **é…ç½®æ¨¡å‹**: é€‰æ‹©APIæä¾›å•†å’Œæ¨¡å‹
    2. **è°ƒæ•´å‚æ•°**: è®¾ç½®æ£€ç´¢æ•°é‡å’Œå¢å¼ºç­–ç•¥
    3. **è¾“å…¥é—®é¢˜**: åœ¨ä¸»ç•Œé¢è¾“å…¥é—®é¢˜
    4. **é€‰æ‹©ç±»å‹**: é€‰æ‹©æœŸæœ›çš„ç­”æ¡ˆç±»å‹
    5. **æŸ¥çœ‹ç»“æœ**: ç³»ç»Ÿè¿”å›ç­”æ¡ˆå’Œåˆ†æè¿‡ç¨‹
    
    **ç­”æ¡ˆç±»å‹è¯´æ˜**:
    - `jingpan`: é‡‘ç›˜ç§‘æŠ€ä¸“ç”¨ï¼ˆä¸­æ–‡è´¢åŠ¡ï¼‰
    - `number`: æ•°å­—ç±»ç­”æ¡ˆ
    - `boolean`: æ˜¯/å¦ç±»ç­”æ¡ˆ
    - `name`: å•ä¸ªåç§°
    - `names`: å¤šä¸ªåç§°åˆ—è¡¨
    """)

# ==================== è¯„ä¼°ç»“æœå¯è§†åŒ–è¾…åŠ©å‡½æ•° ====================
@st.cache_data
def load_evaluation_results(val_result_dir: str = "data/val_set/val_result"):
    """åŠ è½½æ‰€æœ‰è¯„ä¼°ç»“æœæ–‡ä»¶"""
    result_dir = Path(val_result_dir)
    if not result_dir.exists():
        return []
    
    results = []
    for json_file in sorted(result_dir.glob("evaluation_*.json"), reverse=True):
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                data['file_name'] = json_file.name
                data['file_path'] = str(json_file)
                results.append(data)
        except Exception as e:
            st.warning(f"åŠ è½½è¯„ä¼°æ–‡ä»¶å¤±è´¥ {json_file.name}: {e}")
    
    return results

def format_config_summary(config: dict) -> str:
    """æ ¼å¼åŒ–é…ç½®æ‘˜è¦"""
    parts = []
    if config.get('use_hyde'):
        parts.append("HYDE")
    if config.get('use_multi_query'):
        mq_methods = []
        if config.get('multi_query_methods', {}).get('synonym'):
            mq_methods.append("åè¯è§£é‡Š")
        if config.get('multi_query_methods', {}).get('subquestion'):
            mq_methods.append("æŒ‡æ ‡æ‹†åˆ†")
        if config.get('multi_query_methods', {}).get('variant'):
            mq_methods.append("æƒ…æ™¯å˜ä½“")
        if mq_methods:
            parts.append(f"Multi-Query({','.join(mq_methods)})")
    if config.get('llm_reranking'):
        parts.append(f"LLMé‡æ’åº(æ ·æœ¬{config.get('rerank_sample_size', 20)})")
    if config.get('expand_upstream'):
        parts.append(f"ä¸Šæ¸¸æ‰©å……(k={config.get('expand_top_k', 5)},Â±{config.get('expand_context_size', 1)})")
    return " | ".join(parts) if parts else "åŸºç¡€é…ç½®"

def find_question_across_results(question: str, evaluation_results: List[dict]) -> List[dict]:
    """åœ¨æ‰€æœ‰è¯„ä¼°ç»“æœä¸­æŸ¥æ‰¾æŸä¸ªé—®é¢˜çš„ç­”æ¡ˆ"""
    matches = []
    for eval_data in evaluation_results:
        for result in eval_data.get('results', []):
            if result.get('question', '').strip() == question.strip():
                matches.append({
                    'config': eval_data.get('config', {}),
                    'config_summary': format_config_summary(eval_data.get('config', {})),
                    'timestamp': eval_data.get('timestamp', ''),
                    'file_name': eval_data.get('file_name', ''),
                    'rag_answer': result.get('rag_answer', ''),
                    'standard_answer': result.get('standard_answer', ''),
                    'score': result.get('score', 0.0),
                    'reasoning': result.get('reasoning', ''),
                    'is_correct': result.get('is_correct', False)
                })
    return matches

# ==================== ä¸»ç•Œé¢ ====================
# ä¸»åŠŸèƒ½é€‰æ‹©
main_tab1, main_tab2 = st.tabs(["ğŸ’¬ é—®ç­”ç³»ç»Ÿ", "ğŸ“Š è¯„ä¼°ç»“æœåˆ†æ"])

with main_tab1:
    st.title("ğŸ¢ é‡‘ç›˜ç§‘æŠ€ RAG é—®ç­”ç³»ç»Ÿ")
    st.markdown("åŸºäº **FAISS + Qwen + æ—¶é—´è·¯ç”±** çš„æ™ºèƒ½è´¢åŠ¡é—®ç­”ç³»ç»Ÿ")
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    if not st.session_state.initialized:
        if initialize_system():
            st.success("âœ… ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸï¼")
            st.rerun()
        else:
            st.stop()
    
    # æ‰¹é‡è¯„ä¼°åŠŸèƒ½
    if st.session_state.get('evaluating', False):
        st.session_state.evaluating = False
        
        st.markdown("---")
        st.markdown("## ğŸ“Š æ‰¹é‡è¯„ä¼°è¿›è¡Œä¸­...")
        
        try:
            # åŠ è½½é—®é¢˜
            questions_df = pd.read_csv("data/val_set/questions_selected_100.csv")
            benchmark_map = load_benchmark_answers("é‡‘ç›˜è´¢æŠ¥æŸ¥è¯¢åœºæ™¯é—®é¢˜benchmark-åŸå…ˆçš„è¡¨æ ¼.csv")
            
            # åˆ›å»ºè¯„ä¼°ç»“æœç›®å½•
            val_result_dir = Path("data/val_set/val_result")
            val_result_dir.mkdir(parents=True, exist_ok=True)
            
            # åˆå§‹åŒ–è¯„ä¼°ç»“æœ
            evaluation_results = []
            total_questions = len(questions_df)
            correct_count = 0
            total_score = 0.0
            
            # æ”¶é›†å„é˜¶æ®µæ—¶é—´
            timing_accumulator = {
                'init_retriever': [],
                'retrieval': [],
                'hyde_expansion': [],
                'multi_query_expansion': [],
                'llm_reranking': [],
                'upstream_expansion': [],
                'format_results': [],
                'generate_answer': [],
                'vector_search': [],
                'total_time': []
            }
            
            # åˆ›å»ºè¿›åº¦æ¡
            progress_bar = st.progress(0)
            status_text = st.empty()
            results_container = st.container()
            
            # åˆå§‹åŒ–APIå¤„ç†å™¨
            api_processor = APIProcessor(provider="qwen")
            company_name = st.session_state.company_name
            config = st.session_state.config
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ä¸“é—¨çš„è¯„ä¼°é…ç½®
            eval_config = st.session_state.get('eval_config', None)
            if eval_config:
                st.info(f"ğŸ“‹ ä½¿ç”¨è‡ªå®šä¹‰è¯„ä¼°é…ç½®: HYDE={eval_config['use_hyde']}, Multi-Query={eval_config['use_multi_query']}, LLMé‡æ’åº={eval_config['llm_reranking']}")
                # ä½¿ç”¨è¯„ä¼°é…ç½®
                config_info = {
                    'top_n_retrieval': eval_config.get('top_n_retrieval', 10),
                    'use_hyde': eval_config.get('use_hyde', True),
                    'use_multi_query': eval_config.get('use_multi_query', True),
                    'multi_query_methods': eval_config.get('multi_query_methods', {'synonym': True, 'subquestion': False, 'variant': False}),
                    'llm_reranking': eval_config.get('llm_reranking', True),
                    'rerank_sample_size': eval_config.get('rerank_sample_size', 20),
                    'expand_upstream': eval_config.get('expand_upstream', False),
                    'expand_top_k': eval_config.get('expand_top_k', 5),
                    'expand_context_size': eval_config.get('expand_context_size', 1),
                    'parent_document_retrieval': True,
                    'parallel_requests': config.get('parallel_requests', 4),
                    'answering_model': config.get('answering_model', 'qwen-max'),
                    'api_provider': config.get('api_provider', 'qwen')
                }
                # ä¸´æ—¶æ›´æ–°processorçš„é…ç½®
                st.session_state.processor.use_hyde = eval_config['use_hyde']
                st.session_state.processor.use_multi_query = eval_config['use_multi_query']
                st.session_state.processor.multi_query_methods = eval_config['multi_query_methods']
                st.session_state.processor.llm_reranking = eval_config['llm_reranking']
                st.session_state.processor.llm_reranking_sample_size = eval_config['rerank_sample_size']
                st.session_state.processor.expand_upstream = eval_config['expand_upstream']
                st.session_state.processor.expand_top_k = eval_config['expand_top_k']
                st.session_state.processor.expand_context_size = eval_config['expand_context_size']
                st.session_state.processor.top_n_retrieval = eval_config['top_n_retrieval']
            else:
                st.info("ğŸ“‹ ä½¿ç”¨å½“å‰æµç¨‹é…ç½®è¿›è¡Œè¯„ä¼°")
                # ä½¿ç”¨å½“å‰é…ç½®
                config_info = {
                    'top_n_retrieval': config.get('top_n_retrieval', 10),
                    'use_hyde': config.get('use_hyde', True),
                    'use_multi_query': config.get('use_multi_query', True),
                    'multi_query_methods': config.get('multi_query_methods', {'synonym': True, 'subquestion': False, 'variant': False}),
                    'llm_reranking': config.get('llm_reranking', True),
                    'rerank_sample_size': config.get('llm_reranking_sample_size', 20),
                    'expand_upstream': config.get('expand_upstream', False),
                    'expand_top_k': config.get('expand_top_k', 5),
                    'expand_context_size': config.get('expand_context_size', 2),
                    'parent_document_retrieval': True,  # é»˜è®¤å¯ç”¨çˆ¶æ–‡æ¡£æ£€ç´¢
                    'parallel_requests': config.get('parallel_requests', 4),
                    'answering_model': config.get('answering_model', 'qwen-max'),
                    'api_provider': config.get('api_provider', 'qwen')
                }
            
            # æ˜¾ç¤ºè¶…å‚æ•°ç¡®è®¤å¯¹è¯æ¡†
            st.markdown("---")
            st.markdown("### ğŸ“‹ è¶…å‚æ•°é…ç½®ç¡®è®¤")
            
            # åˆ›å»ºä¸¤åˆ—æ˜¾ç¤ºé…ç½®
            conf_col1, conf_col2 = st.columns(2)
            
            with conf_col1:
                st.markdown("#### ğŸš€ æ£€ç´¢å¢å¼ºé…ç½®")
                st.markdown(f"- **HYDE**: {'âœ… å¯ç”¨' if config_info['use_hyde'] else 'âŒ å…³é—­'}")
                st.markdown(f"- **Multi-Query**: {'âœ… å¯ç”¨' if config_info['use_multi_query'] else 'âŒ å…³é—­'}")
                if config_info['use_multi_query']:
                    mq_methods = config_info['multi_query_methods']
                    st.markdown(f"  - åè¯è§£é‡Š: {'âœ…' if mq_methods.get('synonym', False) else 'âŒ'}")
                    st.markdown(f"  - æŒ‡æ ‡æ‹†åˆ†: {'âœ…' if mq_methods.get('subquestion', False) else 'âŒ'}")
                    st.markdown(f"  - æƒ…æ™¯å˜ä½“: {'âœ…' if mq_methods.get('variant', False) else 'âŒ'}")
                
                st.markdown("#### ğŸ¯ é‡æ’åºé…ç½®")
                st.markdown(f"- **LLMé‡æ’åº**: {'âœ… å¯ç”¨' if config_info['llm_reranking'] else 'âŒ å…³é—­'}")
                if config_info['llm_reranking']:
                    st.markdown(f"  - æ ·æœ¬æ•°: {config_info['rerank_sample_size']}")
            
            with conf_col2:
                st.markdown("#### ğŸ“Š æ£€ç´¢å‚æ•°")
                st.markdown(f"- **æœ€ç»ˆæ£€ç´¢æ•°é‡**: {config_info['top_n_retrieval']}")
                st.markdown(f"- **çˆ¶æ–‡æ¡£æ£€ç´¢**: {'âœ… å¯ç”¨' if config_info['parent_document_retrieval'] else 'âŒ å…³é—­'}")
                
                st.markdown("#### ğŸ”„ ä¸Šä¸‹æ¸¸æ‰©å……")
                st.markdown(f"- **ä¸Šä¸‹æ¸¸æ‰©å……**: {'âœ… å¯ç”¨' if config_info['expand_upstream'] else 'âŒ å…³é—­'}")
                if config_info['expand_upstream']:
                    st.markdown(f"  - æ‰©å…… top-k: {config_info['expand_top_k']}")
                    st.markdown(f"  - æ‰©å……å¤§å°: Â±{config_info['expand_context_size']} é¡µ")
                
                st.markdown("#### ğŸ¤– æ¨¡å‹é…ç½®")
                st.markdown(f"- **å›ç­”æ¨¡å‹**: {config_info['answering_model']}")
                st.markdown(f"- **å¹¶å‘æ•°**: {config_info['parallel_requests']}")
            
            st.markdown("---")
            st.warning("âš ï¸ è¯„ä¼°å°†ä½¿ç”¨ä¸Šè¿°é…ç½®è¿è¡Œï¼Œé¢„è®¡è€—æ—¶è¾ƒé•¿ã€‚è¯·ç¡®è®¤é…ç½®æ— è¯¯åç»§ç»­ã€‚")
            
            # éå†æ‰€æœ‰é—®é¢˜
            for idx, row in questions_df.iterrows():
                question = str(row.get('æé—®å†…å®¹', '')).strip()
                if not question:
                    continue
                
                # æ›´æ–°è¿›åº¦
                progress = (idx + 1) / total_questions
                status_text.text(f"æ­£åœ¨è¯„ä¼°ç¬¬ {idx + 1}/{total_questions} ä¸ªé—®é¢˜: {question[:50]}...")
                progress_bar.progress(progress)
                
                # è·å–æ ‡å‡†ç­”æ¡ˆ
                standard_answer = get_standard_answer(question, questions_df, benchmark_map)
                if not standard_answer:
                    # å¦‚æœæ²¡æœ‰æ ‡å‡†ç­”æ¡ˆï¼Œè·³è¿‡
                    evaluation_results.append({
                        'question': question,
                        'standard_answer': '',
                        'rag_answer': '',
                        'score': 0.0,
                        'reasoning': 'æ— æ ‡å‡†ç­”æ¡ˆï¼Œè·³è¿‡è¯„ä¼°',
                        'is_correct': False,
                        'skipped': True,
                        'timing': {}
                    })
                    continue
                
                try:
                    # è°ƒç”¨RAGç³»ç»Ÿè·å–ç­”æ¡ˆ
                    full_question = f"{company_name}{question}" if company_name not in question else question
                    answer_dict = st.session_state.processor.get_answer_for_company(
                        company_name=company_name,
                        question=full_question,
                        schema="jingpan",
                        conversation_history=None,
                        progress_callback=None,
                        selected_years=None
                    )
                    
                    rag_answer = str(answer_dict.get("final_answer", answer_dict.get("answer", "N/A")))
                    
                    # æå–æ—¶é—´ä¿¡æ¯
                    timing = answer_dict.get('timing', {})
                    if timing:
                        for key in timing_accumulator:
                            if key in timing:
                                timing_accumulator[key].append(timing[key])
                    
                    # ä½¿ç”¨LLM as Judgeè¯„ä¼°
                    try:
                        eval_result = api_processor.evaluate_answer(
                            question=question,
                            standard_answer=standard_answer,
                            rag_answer=rag_answer,
                            model="qwen-turbo"
                        )
                        
                        # éªŒè¯è¯„ä¼°ç»“æœçš„æœ‰æ•ˆæ€§
                        if not eval_result or not isinstance(eval_result, dict):
                            raise ValueError("è¯„ä¼°ç»“æœä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯")
                        
                        score = eval_result.get('score', 0.0)
                        reasoning = eval_result.get('reasoning', '')
                        
                        # éªŒè¯reasoningä¸ä¸ºç©º
                        if not reasoning or not reasoning.strip():
                            raise ValueError(f"è¯„ä¼°è¿”å›çš„reasoningä¸ºç©ºï¼Œscore={score}")
                        
                        total_score += score
                        is_correct = score >= 0.8
                        if is_correct:
                            correct_count += 1
                        
                        evaluation_results.append({
                            'question': question,
                            'standard_answer': standard_answer,
                            'rag_answer': rag_answer,
                            'score': score,
                            'reasoning': reasoning,
                            'is_correct': is_correct,
                            'skipped': False,
                            'timing': timing
                        })
                        
                    except Exception as eval_error:
                        # è¯„ä¼°å¤±è´¥æ—¶çš„é™çº§å¤„ç†
                        error_msg = str(eval_error)
                        print(f"[WARNING] è¯„ä¼°å¤±è´¥ (é—®é¢˜: {question[:50]}...): {error_msg}")
                        st.warning(f"âš ï¸ é—®é¢˜è¯„ä¼°å¤±è´¥: {error_msg}")
                        
                        # ä½¿ç”¨é»˜è®¤å€¼ï¼Œä½†ä¿ç•™RAGç­”æ¡ˆå’Œæ—¶é—´ä¿¡æ¯
                        evaluation_results.append({
                            'question': question,
                            'standard_answer': standard_answer,
                            'rag_answer': rag_answer,  # ä¿ç•™RAGç­”æ¡ˆ
                            'score': 0.0,
                            'reasoning': f'è¯„ä¼°å¤±è´¥: {error_msg}',
                            'is_correct': False,
                            'skipped': False,
                            'timing': timing  # ä¿ç•™æ—¶é—´ä¿¡æ¯
                        })
                    
                except Exception as e:
                    evaluation_results.append({
                        'question': question,
                        'standard_answer': standard_answer,
                        'rag_answer': '',
                        'score': 0.0,
                        'reasoning': f'è¯„ä¼°å¤±è´¥: {str(e)}',
                        'is_correct': False,
                        'skipped': False,
                        'error': str(e),
                        'timing': {}
                    })
            
            # å®Œæˆè¯„ä¼°
            progress_bar.progress(1.0)
            status_text.text("âœ… è¯„ä¼°å®Œæˆï¼")
            
            # ç»Ÿè®¡ç»“æœ
            evaluated_count = len([r for r in evaluation_results if not r.get('skipped', False)])
            accuracy = correct_count / evaluated_count if evaluated_count > 0 else 0.0
            average_score = total_score / evaluated_count if evaluated_count > 0 else 0.0
            
            # è®¡ç®—å„é˜¶æ®µå¹³å‡ç”¨æ—¶ï¼ˆç²¾ç¡®åˆ°ç§’ï¼‰
            avg_timing = {}
            for key, times in timing_accumulator.items():
                if times:
                    avg_time = sum(times) / len(times)
                    avg_timing[key] = round(avg_time, 2)  # ä¿ç•™2ä½å°æ•°ï¼ˆç²¾ç¡®åˆ°0.01ç§’ï¼‰
                else:
                    avg_timing[key] = 0.0
            
            # è·å–æœ€ç»ˆæ£€ç´¢æ•°é‡ï¼ˆä»é…ç½®ä¸­ï¼‰
            final_retrieval_count = config_info['top_n_retrieval']
            if config_info.get('expand_upstream', False):
                # å¦‚æœæœ‰ä¸Šæ¸¸æ‰©å……ï¼Œæ£€ç´¢æ•°é‡ä¼šæ›´å¤š
                final_retrieval_count = f"{config_info['top_n_retrieval']} + æ‰©å……"
            
            # ä¿å­˜ç»“æœ
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            result_file = val_result_dir / f"evaluation_{timestamp}.json"
            
            result_data = {
                'timestamp': timestamp,
                'total_questions': total_questions,
                'evaluated_count': evaluated_count,
                'correct_count': correct_count,
                'accuracy': accuracy,
                'average_score': average_score,
                'config': config_info,
                'final_retrieval_count': final_retrieval_count,
                'average_timing': avg_timing,
                'results': evaluation_results
            }
            
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(result_data, f, ensure_ascii=False, indent=2)
            
            # æ˜¾ç¤ºç»Ÿè®¡ç»“æœ
            with results_container:
                st.success(f"âœ… è¯„ä¼°å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
                
                col1, col2, col3, col4, col5 = st.columns(5)
                with col1:
                    st.metric("æ€»é—®é¢˜æ•°", total_questions)
                with col2:
                    st.metric("å·²è¯„ä¼°", evaluated_count)
                with col3:
                    st.metric("æ­£ç¡®ç­”æ¡ˆ", correct_count)
                with col4:
                    st.metric("æ­£ç¡®ç‡", f"{accuracy*100:.2f}%")
                with col5:
                    st.metric("å¹³å‡å¾—åˆ†", f"{average_score:.3f}")
                
                # æ˜¾ç¤ºå„é˜¶æ®µå¹³å‡ç”¨æ—¶
                st.markdown("### â±ï¸ å„é˜¶æ®µå¹³å‡ç”¨æ—¶ï¼ˆç§’ï¼‰")
                timing_df = pd.DataFrame([
                    {'é˜¶æ®µ': 'åˆå§‹åŒ–æ£€ç´¢å™¨', 'å¹³å‡ç”¨æ—¶(ç§’)': avg_timing.get('init_retriever', 0.0)},
                    {'é˜¶æ®µ': 'å‘é‡æ£€ç´¢', 'å¹³å‡ç”¨æ—¶(ç§’)': avg_timing.get('retrieval', 0.0)},
                    {'é˜¶æ®µ': 'HYDEæ‰©å±•', 'å¹³å‡ç”¨æ—¶(ç§’)': avg_timing.get('hyde_expansion', 0.0)},
                    {'é˜¶æ®µ': 'Multi-Queryæ‰©å±•', 'å¹³å‡ç”¨æ—¶(ç§’)': avg_timing.get('multi_query_expansion', 0.0)},
                    {'é˜¶æ®µ': 'å‘é‡æœç´¢', 'å¹³å‡ç”¨æ—¶(ç§’)': avg_timing.get('vector_search', 0.0)},
                    {'é˜¶æ®µ': 'LLMé‡æ’åº', 'å¹³å‡ç”¨æ—¶(ç§’)': avg_timing.get('llm_reranking', 0.0)},
                    {'é˜¶æ®µ': 'ä¸Šæ¸¸æ‰©å……', 'å¹³å‡ç”¨æ—¶(ç§’)': avg_timing.get('upstream_expansion', 0.0)},
                    {'é˜¶æ®µ': 'æ ¼å¼åŒ–ç»“æœ', 'å¹³å‡ç”¨æ—¶(ç§’)': avg_timing.get('format_results', 0.0)},
                    {'é˜¶æ®µ': 'ç”Ÿæˆç­”æ¡ˆ', 'å¹³å‡ç”¨æ—¶(ç§’)': avg_timing.get('generate_answer', 0.0)},
                    {'é˜¶æ®µ': 'æ€»ç”¨æ—¶', 'å¹³å‡ç”¨æ—¶(ç§’)': avg_timing.get('total_time', 0.0)},
                ])
                st.dataframe(timing_df, use_container_width=True, hide_index=True)
                
                # æ˜¾ç¤ºè¯¦ç»†ç»“æœè¡¨æ ¼
                st.markdown("### ğŸ“‹ è¯¦ç»†è¯„ä¼°ç»“æœ")
                results_df = pd.DataFrame([
                    {
                        'é—®é¢˜': r['question'][:50] + '...' if len(r['question']) > 50 else r['question'],
                        'æ ‡å‡†ç­”æ¡ˆ': r['standard_answer'][:50] + '...' if len(r.get('standard_answer', '')) > 50 else r.get('standard_answer', ''),
                        'RAGç­”æ¡ˆ': r['rag_answer'][:50] + '...' if len(r.get('rag_answer', '')) > 50 else r.get('rag_answer', ''),
                        'è¯„åˆ†': r['score'],
                        'æ˜¯å¦æ­£ç¡®': 'âœ…' if r['is_correct'] else 'âŒ',
                        'çŠ¶æ€': 'è·³è¿‡' if r.get('skipped', False) else 'å·²è¯„ä¼°'
                    }
                    for r in evaluation_results
                ])
                st.dataframe(results_df, use_container_width=True)
            
        except Exception as e:
            st.error(f"âŒ è¯„ä¼°è¿‡ç¨‹å‡ºé”™: {str(e)}")
            with st.expander("æŸ¥çœ‹è¯¦ç»†é”™è¯¯"):
                st.code(traceback.format_exc())
    
    # é—®ç­”åŒºåŸŸ
    st.markdown("---")

# å¦‚æœç‚¹å‡»äº†ç¤ºä¾‹é—®é¢˜ï¼Œæ˜¾ç¤ºæç¤º
if st.session_state.get('example_clicked', False):
    st.success(f"âœ… å·²é€‰æ‹©ç¤ºä¾‹é—®é¢˜ï¼š**{st.session_state.current_question}**")
    st.session_state.example_clicked = False

# å›ºå®šä½¿ç”¨ jingpan æ¨¡å¼ï¼ˆæ·±åº¦åˆ†ææ¨¡å¼ï¼‰
schema_type = "jingpan"

# æ·»åŠ è¯´æ˜ä¿¡æ¯
st.info("ğŸ’¡ **æ·±åº¦åˆ†ææ¨¡å¼**ï¼šç³»ç»Ÿå°†ä¸ºæ‚¨æä¾›è¯¦ç»†çš„ç­”æ¡ˆã€æ¨ç†è¿‡ç¨‹å’Œæ•°æ®æ¥æºï¼Œé€‚ç”¨äºæ‰€æœ‰ç±»å‹çš„é—®é¢˜ã€‚")

# ä½¿ç”¨åŠ¨æ€ key ä»¥ä¾¿æ¯æ¬¡ç‚¹å‡»ç¤ºä¾‹é—®é¢˜åé‡æ–°æ¸²æŸ“
question_key = f"question_input_{st.session_state.widget_key_counter}"
question_input = st.text_input(
    "ğŸ’¬ è¯·è¾“å…¥æ‚¨çš„é—®é¢˜",
    value=st.session_state.current_question,
    placeholder="ä¾‹å¦‚ï¼š2024å¹´ç¬¬ä¸€å­£åº¦çš„è¥ä¸šæ”¶å…¥æ˜¯å¤šå°‘ï¼Ÿ",
    help="ç³»ç»Ÿä¼šè‡ªåŠ¨æ·»åŠ å…¬å¸åç§°ï¼ˆé‡‘ç›˜ç§‘æŠ€ï¼‰åˆ°é—®é¢˜å‰",
    key=question_key
)

# é—®ç­”æŒ‰é’®
if st.button("ğŸš€ è·å–ç­”æ¡ˆ", type="primary", use_container_width=True):
    if not question_input.strip():
        st.warning("âš ï¸ è¯·è¾“å…¥é—®é¢˜")
    else:
        # ç¡®ä¿é—®é¢˜åŒ…å«å…¬å¸åç§°
        company_name = st.session_state.company_name
        if company_name not in question_input:
            full_question = f"{company_name}{question_input}"
        else:
            full_question = question_input
        
        # æ˜¾ç¤ºé—®é¢˜
        st.markdown(f'<div class="question-box"><b>â“ é—®é¢˜:</b> {full_question}<br><b>ğŸ“ åˆ†ææ¨¡å¼:</b> æ·±åº¦åˆ†æ (jingpan)</div>', 
                   unsafe_allow_html=True)
        
        try:
            # å‡†å¤‡å¯¹è¯å†å²ï¼ˆå¦‚æœå¯ç”¨å¤šè½®å¯¹è¯ï¼‰
            conversation_history = prepare_conversation_history(st.session_state.context_turns)
            
            # æ˜¾ç¤ºå¤šè½®å¯¹è¯çŠ¶æ€
            if conversation_history:
                st.info(f"ğŸ”„ å¤šè½®å¯¹è¯æ¨¡å¼ï¼šä½¿ç”¨æœ€è¿‘ {len(conversation_history)} è½®å¯¹è¯ä½œä¸ºä¸Šä¸‹æ–‡")
            
            # åˆ›å»ºè¿›åº¦æ¡å®¹å™¨
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # å®šä¹‰è¿›åº¦å›è°ƒå‡½æ•°
            def update_progress(stage: str, progress: int):
                """æ›´æ–°è¿›åº¦æ¡çš„å›è°ƒå‡½æ•°"""
                status_text.text(stage)
                progress_bar.progress(progress)
            
            # è·å–é€‰ä¸­çš„å¹´ä»½ï¼ˆå¦‚æœæœ‰ï¼‰
            selected_years = st.session_state.get("selected_years", None)
            
            # è°ƒç”¨é—®ç­”ç³»ç»Ÿï¼Œä¼ å…¥çœŸå®çš„è¿›åº¦å›è°ƒ
            answer_dict = st.session_state.processor.get_answer_for_company(
                company_name=company_name,
                question=full_question,
                schema=schema_type,
                conversation_history=conversation_history,
                progress_callback=update_progress,
                selected_years=selected_years
            )
            
            # å®Œæˆ
            import time
            status_text.text("âœ… å¤„ç†å®Œæˆï¼")
            progress_bar.progress(100)
            time.sleep(0.5)
            
            # æ¸…é™¤è¿›åº¦æ˜¾ç¤º
            progress_bar.empty()
            status_text.empty()
            
            # æ˜¾ç¤ºç­”æ¡ˆï¼ˆä¼ å…¥é—®é¢˜ä»¥ä¾¿æŸ¥æ‰¾æ ‡å‡†ç­”æ¡ˆï¼‰
            format_answer_display(answer_dict, full_question)
            
            # ä¿å­˜åˆ°å†å²
            st.session_state.history.append({
                'timestamp': datetime.now().isoformat(),
                'question': full_question,
                'schema': schema_type,
                'answer': answer_dict
            })
            
            st.success("âœ… é—®ç­”å®Œæˆï¼")
            
        except Exception as e:
            error_msg = str(e)
            
            # ç‰¹æ®Šå¤„ç†400é”™è¯¯ï¼ˆé€šå¸¸æ˜¯Tokenè¶…é™ï¼‰
            if "400" in error_msg or "Bad Request" in error_msg:
                st.error("âŒ **APIè¯·æ±‚å¤±è´¥ï¼š400 Bad Request**")
                st.markdown("""
                **å¯èƒ½åŸå› **ï¼š
                - ğŸš¨ **Tokenè¶…é™**ï¼šä¸Šæ¸¸æ‰©å……å¯¼è‡´ä¸Šä¸‹æ–‡è¿‡é•¿ï¼ˆ46é¡µçº¦36,800 tokensï¼‰
                - âš ï¸ APIå‚æ•°é”™è¯¯æˆ–æ ¼å¼ä¸æ­£ç¡®
                
                **è§£å†³æ–¹æ³•**ï¼š
                1. **é™ä½ expand_top_k**ï¼šä» 10 é™è‡³ 3-5
                2. **é™ä½ expand_context_size**ï¼šä» 2 é™è‡³ 1
                3. **å…³é—­ä¸Šæ¸¸æ‰©å……**ï¼šä½¿ç”¨ä¼ ç»Ÿçš„ä¸‹æ¸¸æ‰©å……æ¨¡å¼
                4. æ£€æŸ¥ä¾§è¾¹æ çš„Tokené¢„ä¼°ï¼Œç¡®ä¿ä¸è¶…è¿‡ 25,000 tokens
                
                **æ¨èé…ç½®**ï¼ˆé€‚åˆå¤§éƒ¨åˆ†åœºæ™¯ï¼‰ï¼š
                - expand_top_k = 5
                - expand_context_size = 1
                - é¢„è®¡Token: ~12,000 âœ…
                """)
            else:
                st.error(f"âŒ å¤„ç†é—®é¢˜æ—¶å‡ºé”™: {error_msg}")
            
            with st.expander("æŸ¥çœ‹è¯¦ç»†é”™è¯¯"):
                st.code(traceback.format_exc())

# ç¤ºä¾‹é—®é¢˜ï¼ˆä»é—®é¢˜åº“åŠ è½½ï¼‰
st.markdown("---")
st.markdown("### ğŸ’¡ æŠ•èµ„è€…å…³æ³¨é—®é¢˜")

# åŠ è½½é—®é¢˜åº“
try:
    questions_df = pd.read_csv("data/val_set/questions_selected_100.csv")
    total_questions = len(questions_df)
    st.markdown(f"ç‚¹å‡»ä¸‹æ–¹é—®é¢˜å¯è‡ªåŠ¨å¡«å…¥è¾“å…¥æ¡† | å½“å‰å…±æœ‰ **{total_questions}** ä¸ªé—®é¢˜")

    ...
    
    # è·å–æ‰€æœ‰é—®é¢˜ç±»å‹
    question_types = questions_df['é—®é¢˜ç±»å‹'].unique().tolist()
    
    # åˆ›å»ºé—®é¢˜ç±»å‹é€‰æ‹©å™¨
    col_select, col_random = st.columns([3, 1])
    
    with col_select:
        selected_type = st.selectbox(
            "é€‰æ‹©é—®é¢˜ç±»å‹",
            options=["å…¨éƒ¨"] + sorted(question_types),
            index=0,
            key="question_type_selector"
        )
    
    with col_random:
        if st.button("ğŸ² éšæœºé—®é¢˜", use_container_width=True):
            random_q = questions_df.sample(1)['æé—®å†…å®¹'].values[0]
            st.session_state.current_question = random_q
            st.session_state.current_schema = "jingpan"
            st.session_state.example_clicked = True
            st.session_state.widget_key_counter += 1
            st.rerun()
    
    # ç­›é€‰é—®é¢˜
    if selected_type == "å…¨éƒ¨":
        filtered_questions = questions_df
    else:
        filtered_questions = questions_df[questions_df['é—®é¢˜ç±»å‹'] == selected_type]
    
    # æ˜¾ç¤ºé—®é¢˜ç»Ÿè®¡
    st.info(f"ğŸ“Š å½“å‰ç±»å‹å…± **{len(filtered_questions)}** ä¸ªé—®é¢˜")
    
    # åˆ†3åˆ—å±•ç¤ºé—®é¢˜
    col1, col2, col3 = st.columns(3)
    
    # å°†é—®é¢˜åˆ†é…åˆ°3åˆ—
    questions_list = filtered_questions['æé—®å†…å®¹'].tolist()
    
    # æœ€å¤šæ˜¾ç¤º15ä¸ªé—®é¢˜ï¼ˆé¿å…é¡µé¢è¿‡é•¿ï¼‰
    display_limit = 15
    if len(questions_list) > display_limit:
        questions_list = questions_list[:display_limit]
        st.warning(f"âš ï¸ ä»…æ˜¾ç¤ºå‰ {display_limit} ä¸ªé—®é¢˜ï¼Œå¯é€šè¿‡ç±»å‹ç­›é€‰æŸ¥çœ‹æ›´å¤š")
    
    # å¹³å‡åˆ†é…åˆ°3åˆ—
    questions_per_col = len(questions_list) // 3 + (1 if len(questions_list) % 3 > 0 else 0)
    
    for idx, col in enumerate([col1, col2, col3]):
        with col:
            start_idx = idx * questions_per_col
            end_idx = min((idx + 1) * questions_per_col, len(questions_list))
            
            for i in range(start_idx, end_idx):
                q = questions_list[i]
                # æˆªæ–­è¿‡é•¿çš„é—®é¢˜ç”¨äºæŒ‰é’®æ˜¾ç¤º
                button_text = q if len(q) <= 50 else q[:47] + "..."
                
                if st.button(button_text, key=f"ex_q_{i}_{hash(q) % 10000}", use_container_width=True):
                    # æ›´æ–°é—®é¢˜ï¼ˆå›ºå®šä½¿ç”¨ jingpanï¼‰
                    st.session_state.current_question = q
                    st.session_state.current_schema = "jingpan"
                    st.session_state.example_clicked = True
                    # å¢åŠ è®¡æ•°å™¨ï¼Œå¼ºåˆ¶é‡æ–°æ¸²æŸ“è¾“å…¥æ¡†
                    st.session_state.widget_key_counter += 1
                    st.rerun()

except FileNotFoundError:
    st.warning("âš ï¸ é—®é¢˜åº“æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œæ˜¾ç¤ºé»˜è®¤ç¤ºä¾‹é—®é¢˜")
    
    # é»˜è®¤ç¤ºä¾‹é—®é¢˜ï¼ˆä½œä¸ºåå¤‡ï¼‰
    example_col1, example_col2 = st.columns(2)
    
    with example_col1:
        st.markdown("**ğŸ“Š è´¢åŠ¡æ•°æ®ç±»**")
        examples_financial = [
            "2024å¹´ç¬¬ä¸€å­£åº¦çš„è¥ä¸šæ”¶å…¥æ˜¯å¤šå°‘ï¼Ÿ",
            "2023å¹´åˆ°2025å¹´çš„å‡€åˆ©æ¶¦å¯¹æ¯”",
            "æˆªè‡³2025å¹´9æœˆ30æ—¥çš„æ€»èµ„äº§",
        ]
        for q in examples_financial:
            if st.button(q, key=f"ex_fin_{q[:10]}", use_container_width=True):
                st.session_state.current_question = q
                st.session_state.current_schema = "jingpan"
                st.session_state.example_clicked = True
                st.session_state.widget_key_counter += 1
                st.rerun()
    
    with example_col2:
        st.markdown("**ğŸ“ ä¿¡æ¯æŸ¥è¯¢ç±»**")
        examples_info = [
            "å…¬å¸çš„æ³•å®šä»£è¡¨äººæ˜¯è°ï¼Ÿ",
            "2024å¹´æœ‰å“ªäº›ä¸»è¦äº§å“ï¼Ÿ",
            "å…¬å¸æ˜¯å¦æœ‰æµ·å¤–ä¸šåŠ¡ï¼Ÿ",
        ]
        for q in examples_info:
            if st.button(q, key=f"ex_info_{q[:10]}", use_container_width=True):
                st.session_state.current_question = q
                st.session_state.current_schema = "jingpan"
                st.session_state.example_clicked = True
                st.session_state.widget_key_counter += 1
                st.rerun()

except Exception as e:
    st.error(f"âŒ åŠ è½½é—®é¢˜åº“æ—¶å‡ºé”™: {str(e)}")

# å†å²è®°å½•å±•ç¤º
if st.session_state.history:
    st.markdown("---")
    st.markdown("### ğŸ“œ é—®ç­”å†å²")
    
    with st.expander(f"æŸ¥çœ‹å†å²è®°å½•ï¼ˆå…± {len(st.session_state.history)} æ¡ï¼‰", expanded=False):
        for i, record in enumerate(reversed(st.session_state.history), 1):
            # ä½¿ç”¨æ›´æ¸…æ™°çš„å®¹å™¨å±•ç¤ºæ¯æ¡è®°å½•
            with st.container():
                st.markdown(f"#### ğŸ“‹ è®°å½• {i}")
                st.markdown(f"ğŸ• **æ—¶é—´**: {record['timestamp']}")
                st.markdown(f"â“ **é—®é¢˜**: {record['question']}")
                st.markdown(f"ğŸ“ **ç±»å‹**: `{record['schema']}`")
                
                answer = record['answer'].get('final_answer', record['answer'].get('answer', 'N/A'))
                st.markdown(f"ğŸ’¡ **ç­”æ¡ˆ**: **{answer}**")
                st.markdown("---")

with main_tab2:
    st.title("ğŸ“Š è¯„ä¼°ç»“æœåˆ†æ")
    st.markdown("åˆ†æä¸åŒå‚æ•°é…ç½®ä¸‹çš„è¯„ä¼°ç»“æœï¼Œå¯¹æ¯”ç­”æ¡ˆå·®å¼‚å’Œç»Ÿè®¡æŒ‡æ ‡")
    
    # åŠ è½½è¯„ä¼°ç»“æœ
    evaluation_results = load_evaluation_results()
    
    if not evaluation_results:
        st.warning("âš ï¸ æœªæ‰¾åˆ°è¯„ä¼°ç»“æœæ–‡ä»¶ã€‚è¯·å…ˆè¿è¡Œæ‰¹é‡è¯„ä¼°ã€‚")
        st.info("è¯„ä¼°ç»“æœæ–‡ä»¶åº”ä½äº: `data/val_set/val_result/evaluation_*.json`")
    else:
        st.success(f"âœ… å·²åŠ è½½ {len(evaluation_results)} ä¸ªè¯„ä¼°ç»“æœæ–‡ä»¶")
        
        # åŠŸèƒ½é€‰æ‹©
        analysis_mode = st.radio(
            "é€‰æ‹©åˆ†ææ¨¡å¼",
            ["é—®é¢˜å¯¹æ¯”", "é…ç½®ç»Ÿè®¡"],
            horizontal=True,
            key="analysis_mode"
        )
        
        if analysis_mode == "é—®é¢˜å¯¹æ¯”":
            st.markdown("### ğŸ” é—®é¢˜å¯¹æ¯”åˆ†æ")
            st.markdown("æŸ¥çœ‹æŸä¸ªé—®é¢˜åœ¨ä¸åŒå‚æ•°é…ç½®ä¸‹çš„å›ç­”å·®å¼‚")
            
            # è·å–æ‰€æœ‰é—®é¢˜åˆ—è¡¨
            all_questions = set()
            for eval_data in evaluation_results:
                for result in eval_data.get('results', []):
                    all_questions.add(result.get('question', '').strip())
            
            if all_questions:
                selected_question = st.selectbox(
                    "é€‰æ‹©è¦å¯¹æ¯”çš„é—®é¢˜",
                    sorted(all_questions),
                    key="question_compare_select"
                )
                
                if selected_question:
                    # æŸ¥æ‰¾è¯¥é—®é¢˜åœ¨æ‰€æœ‰è¯„ä¼°ç»“æœä¸­çš„ç­”æ¡ˆ
                    matches = find_question_across_results(selected_question, evaluation_results)
                    
                    if matches:
                        st.markdown(f"#### ğŸ“‹ æ‰¾åˆ° {len(matches)} ä¸ªé…ç½®ä¸‹çš„ç­”æ¡ˆ")
                        
                        # æ˜¾ç¤ºæ ‡å‡†ç­”æ¡ˆ
                        if matches[0].get('standard_answer'):
                            st.info(f"ğŸ“Œ **æ ‡å‡†ç­”æ¡ˆ**: {matches[0]['standard_answer']}")
                        
                        # æ˜¾ç¤ºæ¯ä¸ªé…ç½®çš„ç­”æ¡ˆ
                        for i, match in enumerate(matches, 1):
                            with st.expander(
                                f"é…ç½® {i}: {match['config_summary']} | "
                                f"å¾—åˆ†: {match['score']:.2f} | "
                                f"{'âœ… æ­£ç¡®' if match['is_correct'] else 'âŒ é”™è¯¯'} | "
                                f"æ—¶é—´: {match['timestamp']}",
                                expanded=(i == 1)
                            ):
                                col1, col2 = st.columns([2, 1])
                                
                                with col1:
                                    st.markdown("**RAGç”Ÿæˆçš„ç­”æ¡ˆ:**")
                                    st.write(match['rag_answer'])
                                
                                with col2:
                                    st.metric("è¯„åˆ†", f"{match['score']:.2f}")
                                    st.metric("æ˜¯å¦æ­£ç¡®", "âœ…" if match['is_correct'] else "âŒ")
                                
                                if match.get('reasoning'):
                                    st.markdown("**è¯„ä¼°ç†ç”±:**")
                                    st.caption(match['reasoning'])
                                
                                st.caption(f"æ–‡ä»¶: {match['file_name']}")
                        
                        # å¯¹æ¯”è¡¨æ ¼
                        st.markdown("#### ğŸ“Š å¯¹æ¯”è¡¨æ ¼")
                        compare_df = pd.DataFrame([
                            {
                                'é…ç½®': match['config_summary'],
                                'å¾—åˆ†': match['score'],
                                'æ˜¯å¦æ­£ç¡®': 'âœ…' if match['is_correct'] else 'âŒ',
                                'RAGç­”æ¡ˆ': match['rag_answer'][:100] + '...' if len(match['rag_answer']) > 100 else match['rag_answer'],
                                'æ—¶é—´': match['timestamp']
                            }
                            for match in matches
                        ])
                        st.dataframe(compare_df, use_container_width=True, hide_index=True)
                    else:
                        st.warning("æœªæ‰¾åˆ°è¯¥é—®é¢˜çš„è¯„ä¼°ç»“æœ")
            else:
                st.warning("æœªæ‰¾åˆ°ä»»ä½•é—®é¢˜")
        
        elif analysis_mode == "é…ç½®ç»Ÿè®¡":
            st.markdown("### ğŸ“ˆ é…ç½®ç»Ÿè®¡ä¿¡æ¯")
            st.markdown("æŸ¥çœ‹æŸä¸ªå‚æ•°é…ç½®çš„è¯„ä¼°ç»Ÿè®¡ç»“æœ")
            
            # é€‰æ‹©è¯„ä¼°æ–‡ä»¶
            eval_options = [
                f"{eval_data['timestamp']} | {format_config_summary(eval_data.get('config', {}))} | "
                f"å‡†ç¡®ç‡: {eval_data.get('accuracy', 0)*100:.1f}%"
                for eval_data in evaluation_results
            ]
            
            selected_idx = st.selectbox(
                "é€‰æ‹©è¯„ä¼°ç»“æœ",
                range(len(evaluation_results)),
                format_func=lambda x: eval_options[x],
                key="config_stats_select"
            )
            
            if selected_idx is not None:
                selected_eval = evaluation_results[selected_idx]
                config = selected_eval.get('config', {})
                
                # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
                st.markdown("#### âš™ï¸ é…ç½®å‚æ•°")
                config_cols = st.columns(3)
                
                with config_cols[0]:
                    st.markdown("**æ£€ç´¢å¢å¼º:**")
                    st.write(f"- HYDE: {'âœ…' if config.get('use_hyde') else 'âŒ'}")
                    st.write(f"- Multi-Query: {'âœ…' if config.get('use_multi_query') else 'âŒ'}")
                    if config.get('use_multi_query'):
                        mq = config.get('multi_query_methods', {})
                        st.write(f"  - åè¯è§£é‡Š: {'âœ…' if mq.get('synonym') else 'âŒ'}")
                        st.write(f"  - æŒ‡æ ‡æ‹†åˆ†: {'âœ…' if mq.get('subquestion') else 'âŒ'}")
                        st.write(f"  - æƒ…æ™¯å˜ä½“: {'âœ…' if mq.get('variant') else 'âŒ'}")
                
                with config_cols[1]:
                    st.markdown("**é‡æ’åºä¸æ‰©å……:**")
                    st.write(f"- LLMé‡æ’åº: {'âœ…' if config.get('llm_reranking') else 'âŒ'}")
                    if config.get('llm_reranking'):
                        st.write(f"  - æ ·æœ¬æ•°: {config.get('rerank_sample_size', 'N/A')}")
                    st.write(f"- ä¸Šæ¸¸æ‰©å……: {'âœ…' if config.get('expand_upstream') else 'âŒ'}")
                    if config.get('expand_upstream'):
                        st.write(f"  - Top-K: {config.get('expand_top_k', 'N/A')}")
                        st.write(f"  - æ‰©å……å¤§å°: Â±{config.get('expand_context_size', 'N/A')}é¡µ")
                
                with config_cols[2]:
                    st.markdown("**å…¶ä»–å‚æ•°:**")
                    st.write(f"- æœ€ç»ˆæ£€ç´¢æ•°: {config.get('top_n_retrieval', 'N/A')}")
                    st.write(f"- å›ç­”æ¨¡å‹: {config.get('answering_model', 'N/A')}")
                    st.write(f"- å¹¶å‘æ•°: {config.get('parallel_requests', 'N/A')}")
                
                st.markdown("---")
                
                # æ˜¾ç¤ºç»Ÿè®¡æŒ‡æ ‡
                st.markdown("#### ğŸ“Š è¯„ä¼°ç»Ÿè®¡")
                stat_cols = st.columns(5)
                
                with stat_cols[0]:
                    st.metric("æ€»é—®é¢˜æ•°", selected_eval.get('total_questions', 0))
                with stat_cols[1]:
                    st.metric("å·²è¯„ä¼°", selected_eval.get('evaluated_count', 0))
                with stat_cols[2]:
                    st.metric("æ­£ç¡®ç­”æ¡ˆ", selected_eval.get('correct_count', 0))
                with stat_cols[3]:
                    accuracy = selected_eval.get('accuracy', 0)
                    st.metric("å‡†ç¡®ç‡", f"{accuracy*100:.2f}%")
                with stat_cols[4]:
                    st.metric("å¹³å‡å¾—åˆ†", f"{selected_eval.get('average_score', 0):.3f}")
                
                # æ˜¾ç¤ºæ—¶é—´ç»Ÿè®¡
                avg_timing = selected_eval.get('average_timing', {})
                if avg_timing:
                    st.markdown("#### â±ï¸ å¹³å‡ç”¨æ—¶ï¼ˆç§’ï¼‰")
                    timing_df = pd.DataFrame([
                        {'é˜¶æ®µ': 'åˆå§‹åŒ–æ£€ç´¢å™¨', 'å¹³å‡ç”¨æ—¶(ç§’)': avg_timing.get('init_retriever', 0.0)},
                        {'é˜¶æ®µ': 'å‘é‡æ£€ç´¢', 'å¹³å‡ç”¨æ—¶(ç§’)': avg_timing.get('retrieval', 0.0)},
                        {'é˜¶æ®µ': 'HYDEæ‰©å±•', 'å¹³å‡ç”¨æ—¶(ç§’)': avg_timing.get('hyde_expansion', 0.0)},
                        {'é˜¶æ®µ': 'Multi-Queryæ‰©å±•', 'å¹³å‡ç”¨æ—¶(ç§’)': avg_timing.get('multi_query_expansion', 0.0)},
                        {'é˜¶æ®µ': 'LLMé‡æ’åº', 'å¹³å‡ç”¨æ—¶(ç§’)': avg_timing.get('llm_reranking', 0.0)},
                        {'é˜¶æ®µ': 'ä¸Šæ¸¸æ‰©å……', 'å¹³å‡ç”¨æ—¶(ç§’)': avg_timing.get('upstream_expansion', 0.0)},
                        {'é˜¶æ®µ': 'ç”Ÿæˆç­”æ¡ˆ', 'å¹³å‡ç”¨æ—¶(ç§’)': avg_timing.get('generate_answer', 0.0)},
                        {'é˜¶æ®µ': 'æ€»ç”¨æ—¶', 'å¹³å‡ç”¨æ—¶(ç§’)': avg_timing.get('total_time', 0.0)},
                    ])
                    st.dataframe(timing_df, use_container_width=True, hide_index=True)
                
                # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
                st.markdown("#### ğŸ“‹ è¯¦ç»†è¯„ä¼°ç»“æœ")
                results = selected_eval.get('results', [])
                if results:
                    results_df = pd.DataFrame([
                        {
                            'é—®é¢˜': r.get('question', '')[:60] + '...' if len(r.get('question', '')) > 60 else r.get('question', ''),
                            'æ ‡å‡†ç­”æ¡ˆ': r.get('standard_answer', '')[:60] + '...' if len(r.get('standard_answer', '')) > 60 else r.get('standard_answer', ''),
                            'RAGç­”æ¡ˆ': r.get('rag_answer', '')[:60] + '...' if len(r.get('rag_answer', '')) > 60 else r.get('rag_answer', ''),
                            'è¯„åˆ†': r.get('score', 0.0),
                            'æ˜¯å¦æ­£ç¡®': 'âœ…' if r.get('is_correct', False) else 'âŒ',
                            'è¯„ä¼°ç†ç”±': r.get('reasoning', '')[:80] + '...' if len(r.get('reasoning', '')) > 80 else r.get('reasoning', '')
                        }
                        for r in results
                    ])
                    st.dataframe(results_df, use_container_width=True, hide_index=True)
                    
                    # ä¸‹è½½æŒ‰é’®
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½å®Œæ•´è¯„ä¼°ç»“æœ (JSON)",
                        data=json.dumps(selected_eval, ensure_ascii=False, indent=2),
                        file_name=selected_eval.get('file_name', 'evaluation_result.json'),
                        mime="application/json"
                    )
                else:
                    st.warning("è¯¥è¯„ä¼°ç»“æœä¸­æ²¡æœ‰è¯¦ç»†æ•°æ®")

# é¡µè„š
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; font-size: 0.9rem;">
    <p>ğŸ”§ é‡‘ç›˜ç§‘æŠ€ RAG é—®ç­”ç³»ç»Ÿ | åŸºäº FAISS + Qwen-max + æ—¶é—´æ™ºèƒ½è·¯ç”±</p>
    <p>ğŸ’¡ æ”¯æŒå¤šå¹´ä»½å¯¹æ¯”ã€æ™ºèƒ½æ£€ç´¢å¢å¼ºï¼ˆHYDE + Multi-Query + LLMé‡æ’åºï¼‰</p>
</div>
""", unsafe_allow_html=True)
